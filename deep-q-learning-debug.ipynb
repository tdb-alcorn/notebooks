{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepQNet:\n",
    "    def __init__(self,\n",
    "                 learning_rate=1e-2,\n",
    "                 state_shape=4,\n",
    "                 num_actions=2,\n",
    "                 hidden=16,\n",
    "                 name='DeepQNet'\n",
    "                ):\n",
    "        with tf.variable_scope(name):\n",
    "            self.state = tf.placeholder(tf.float32, [None, state_shape], name='state')\n",
    "            self.action = tf.placeholder(tf.int32, [None], name='action')\n",
    "            action_one_hot = tf.one_hot(self.action, num_actions)\n",
    "            \n",
    "            self.target = tf.placeholder(tf.float32, [None], name='target')\n",
    "            \n",
    "            self.hidden0 = tf.contrib.layers.fully_connected(self.state, hidden)\n",
    "            self.hidden1 = tf.contrib.layers.fully_connected(self.hidden0, hidden)\n",
    "            \n",
    "            self.value = tf.contrib.layers.fully_connected(self.hidden1, num_actions,\n",
    "                                                           activation_fn=None)\n",
    "            \n",
    "            self.predicted_reward = tf.reduce_sum(tf.multiply(self.value, action_one_hot), axis=1)\n",
    "            \n",
    "            self.loss = tf.reduce_mean(tf.square(self.target - self.predicted_reward))\n",
    "            self.opt = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(self.loss)\n",
    "\n",
    "class Memory():\n",
    "    def __init__(self, max_size=1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "    \n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "            \n",
    "    def sample(self, batch_size):\n",
    "        idx = np.random.choice(np.arange(len(self.buffer)), \n",
    "                               size=batch_size, \n",
    "                               replace=False)\n",
    "        return [self.buffer[ii] for ii in idx]\n",
    "    \n",
    "def play(env_name, agent):\n",
    "    env = gym.make(env_name)\n",
    "    try:\n",
    "        with tf.Session() as sess:\n",
    "            saver.restore(sess, \"checkpoints/cartpole.ckpt\")\n",
    "            state = env.reset()\n",
    "            action = env.action_space.sample()\n",
    "            env.render()\n",
    "            state, reward, done, info = env.step(action)\n",
    "            env.render()\n",
    "            done = False\n",
    "            total_reward = 0\n",
    "            total_reward += reward\n",
    "            while not done:\n",
    "                value = sess.run(agent.value, feed_dict={\n",
    "                    agent.state: [state],\n",
    "                })\n",
    "                action = np.argmax(value)\n",
    "                state, reward, done, info = env.step(action)\n",
    "                total_reward += reward\n",
    "                print(state, action, reward)\n",
    "                env.render()\n",
    "            print(total_reward)\n",
    "    finally:\n",
    "        env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_episodes = 1000          # max number of episodes to learn from\n",
    "max_steps = 200                # max steps in an episode\n",
    "gamma = 0.99                   # future reward discount\n",
    "\n",
    "# Exploration parameters\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01            # minimum exploration probability \n",
    "decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "hidden_size = 64               # number of units in each Q-network hidden layer\n",
    "learning_rate = 0.0001         # Q-network learning rate\n",
    "\n",
    "# Memory parameters\n",
    "memory_size = 10000            # memory capacity\n",
    "batch_size = 20                # experience mini-batch size\n",
    "pretrain_length = batch_size   # number experiences to pretrain the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Seeding memory...\n",
      "Running training...\n",
      "Episode: 0 Total reward: 9.0 Training loss: 1.3202 Epsilon: 0.9991\n",
      "Episode: 1 Total reward: 26.0 Training loss: 1.2901 Epsilon: 0.9965\n",
      "Episode: 2 Total reward: 37.0 Training loss: 1.5444 Epsilon: 0.9929\n",
      "Episode: 3 Total reward: 24.0 Training loss: 1.2669 Epsilon: 0.9905\n",
      "Episode: 4 Total reward: 21.0 Training loss: 0.9769 Epsilon: 0.9885\n",
      "Episode: 5 Total reward: 22.0 Training loss: 1.4089 Epsilon: 0.9863\n",
      "Episode: 6 Total reward: 52.0 Training loss: 1.2830 Epsilon: 0.9813\n",
      "Episode: 7 Total reward: 12.0 Training loss: 1.2137 Epsilon: 0.9801\n",
      "Episode: 8 Total reward: 16.0 Training loss: 1.2570 Epsilon: 0.9786\n",
      "Episode: 9 Total reward: 21.0 Training loss: 1.2114 Epsilon: 0.9765\n",
      "Episode: 10 Total reward: 23.0 Training loss: 1.4420 Epsilon: 0.9743\n",
      "Episode: 11 Total reward: 40.0 Training loss: 1.8219 Epsilon: 0.9705\n",
      "Episode: 12 Total reward: 22.0 Training loss: 1.3961 Epsilon: 0.9683\n",
      "Episode: 13 Total reward: 20.0 Training loss: 1.3198 Epsilon: 0.9664\n",
      "Episode: 14 Total reward: 23.0 Training loss: 1.0810 Epsilon: 0.9642\n",
      "Episode: 15 Total reward: 13.0 Training loss: 1.4246 Epsilon: 0.9630\n",
      "Episode: 16 Total reward: 16.0 Training loss: 1.2483 Epsilon: 0.9615\n",
      "Episode: 17 Total reward: 53.0 Training loss: 2.0543 Epsilon: 0.9564\n",
      "Episode: 18 Total reward: 24.0 Training loss: 1.5971 Epsilon: 0.9542\n",
      "Episode: 19 Total reward: 23.0 Training loss: 1.4728 Epsilon: 0.9520\n",
      "Episode: 20 Total reward: 44.0 Training loss: 2.0152 Epsilon: 0.9479\n",
      "Episode: 21 Total reward: 29.0 Training loss: 2.0787 Epsilon: 0.9451\n",
      "Episode: 22 Total reward: 14.0 Training loss: 2.4331 Epsilon: 0.9438\n",
      "Episode: 23 Total reward: 19.0 Training loss: 2.5068 Epsilon: 0.9421\n",
      "Episode: 24 Total reward: 14.0 Training loss: 1.8927 Epsilon: 0.9408\n",
      "Episode: 25 Total reward: 27.0 Training loss: 2.6494 Epsilon: 0.9383\n",
      "Episode: 26 Total reward: 45.0 Training loss: 1.9866 Epsilon: 0.9341\n",
      "Episode: 27 Total reward: 16.0 Training loss: 2.4845 Epsilon: 0.9326\n",
      "Episode: 28 Total reward: 23.0 Training loss: 3.1684 Epsilon: 0.9305\n",
      "Episode: 29 Total reward: 11.0 Training loss: 3.7224 Epsilon: 0.9295\n",
      "Episode: 30 Total reward: 10.0 Training loss: 6.4715 Epsilon: 0.9286\n",
      "Episode: 31 Total reward: 18.0 Training loss: 3.2857 Epsilon: 0.9269\n",
      "Episode: 32 Total reward: 10.0 Training loss: 3.7445 Epsilon: 0.9260\n",
      "Episode: 33 Total reward: 19.0 Training loss: 11.1795 Epsilon: 0.9243\n",
      "Episode: 34 Total reward: 17.0 Training loss: 19.3376 Epsilon: 0.9227\n",
      "Episode: 35 Total reward: 7.0 Training loss: 4.5677 Epsilon: 0.9221\n",
      "Episode: 36 Total reward: 19.0 Training loss: 4.8910 Epsilon: 0.9203\n",
      "Episode: 37 Total reward: 8.0 Training loss: 7.7192 Epsilon: 0.9196\n",
      "Episode: 38 Total reward: 14.0 Training loss: 4.8875 Epsilon: 0.9183\n",
      "Episode: 39 Total reward: 19.0 Training loss: 7.1561 Epsilon: 0.9166\n",
      "Episode: 40 Total reward: 14.0 Training loss: 11.7447 Epsilon: 0.9153\n",
      "Episode: 41 Total reward: 14.0 Training loss: 4.2890 Epsilon: 0.9141\n",
      "Episode: 42 Total reward: 10.0 Training loss: 29.8373 Epsilon: 0.9132\n",
      "Episode: 43 Total reward: 11.0 Training loss: 9.7532 Epsilon: 0.9122\n",
      "Episode: 44 Total reward: 8.0 Training loss: 4.4538 Epsilon: 0.9115\n",
      "Episode: 45 Total reward: 13.0 Training loss: 5.9941 Epsilon: 0.9103\n",
      "Episode: 46 Total reward: 18.0 Training loss: 5.3271 Epsilon: 0.9087\n",
      "Episode: 47 Total reward: 31.0 Training loss: 27.2378 Epsilon: 0.9059\n",
      "Episode: 48 Total reward: 17.0 Training loss: 4.4991 Epsilon: 0.9044\n",
      "Episode: 49 Total reward: 14.0 Training loss: 42.5032 Epsilon: 0.9031\n",
      "Episode: 50 Total reward: 32.0 Training loss: 16.2955 Epsilon: 0.9003\n",
      "Episode: 51 Total reward: 16.0 Training loss: 17.2678 Epsilon: 0.8988\n",
      "Episode: 52 Total reward: 29.0 Training loss: 7.5816 Epsilon: 0.8963\n",
      "Episode: 53 Total reward: 12.0 Training loss: 20.9505 Epsilon: 0.8952\n",
      "Episode: 54 Total reward: 20.0 Training loss: 8.9029 Epsilon: 0.8934\n",
      "Episode: 55 Total reward: 68.0 Training loss: 6.2691 Epsilon: 0.8874\n",
      "Episode: 56 Total reward: 20.0 Training loss: 6.9513 Epsilon: 0.8857\n",
      "Episode: 57 Total reward: 12.0 Training loss: 70.7735 Epsilon: 0.8846\n",
      "Episode: 58 Total reward: 32.0 Training loss: 20.2090 Epsilon: 0.8818\n",
      "Episode: 59 Total reward: 61.0 Training loss: 26.8850 Epsilon: 0.8765\n",
      "Episode: 60 Total reward: 10.0 Training loss: 41.0939 Epsilon: 0.8757\n",
      "Episode: 61 Total reward: 13.0 Training loss: 127.5767 Epsilon: 0.8745\n",
      "Episode: 62 Total reward: 14.0 Training loss: 7.4337 Epsilon: 0.8733\n",
      "Episode: 63 Total reward: 15.0 Training loss: 7.4609 Epsilon: 0.8720\n",
      "Episode: 64 Total reward: 33.0 Training loss: 11.1279 Epsilon: 0.8692\n",
      "Episode: 65 Total reward: 13.0 Training loss: 21.3633 Epsilon: 0.8681\n",
      "Episode: 66 Total reward: 9.0 Training loss: 7.4735 Epsilon: 0.8673\n",
      "Episode: 67 Total reward: 8.0 Training loss: 9.2723 Epsilon: 0.8666\n",
      "Episode: 68 Total reward: 20.0 Training loss: 33.2940 Epsilon: 0.8649\n",
      "Episode: 69 Total reward: 11.0 Training loss: 13.7986 Epsilon: 0.8640\n",
      "Episode: 70 Total reward: 11.0 Training loss: 79.2830 Epsilon: 0.8630\n",
      "Episode: 71 Total reward: 8.0 Training loss: 31.1502 Epsilon: 0.8624\n",
      "Episode: 72 Total reward: 12.0 Training loss: 97.2147 Epsilon: 0.8613\n",
      "Episode: 73 Total reward: 17.0 Training loss: 30.1268 Epsilon: 0.8599\n",
      "Episode: 74 Total reward: 18.0 Training loss: 8.8534 Epsilon: 0.8584\n",
      "Episode: 75 Total reward: 10.0 Training loss: 8.4194 Epsilon: 0.8575\n",
      "Episode: 76 Total reward: 14.0 Training loss: 56.1158 Epsilon: 0.8563\n",
      "Episode: 77 Total reward: 17.0 Training loss: 64.5562 Epsilon: 0.8549\n",
      "Episode: 78 Total reward: 9.0 Training loss: 152.4511 Epsilon: 0.8541\n",
      "Episode: 79 Total reward: 14.0 Training loss: 63.3806 Epsilon: 0.8529\n",
      "Episode: 80 Total reward: 23.0 Training loss: 147.7262 Epsilon: 0.8510\n",
      "Episode: 81 Total reward: 16.0 Training loss: 196.7675 Epsilon: 0.8497\n",
      "Episode: 82 Total reward: 11.0 Training loss: 8.9511 Epsilon: 0.8487\n",
      "Episode: 83 Total reward: 13.0 Training loss: 7.9135 Epsilon: 0.8477\n",
      "Episode: 84 Total reward: 56.0 Training loss: 6.6892 Epsilon: 0.8430\n",
      "Episode: 85 Total reward: 27.0 Training loss: 8.1581 Epsilon: 0.8407\n",
      "Episode: 86 Total reward: 14.0 Training loss: 54.5630 Epsilon: 0.8396\n",
      "Episode: 87 Total reward: 18.0 Training loss: 76.3711 Epsilon: 0.8381\n",
      "Episode: 88 Total reward: 14.0 Training loss: 27.4072 Epsilon: 0.8369\n",
      "Episode: 89 Total reward: 22.0 Training loss: 8.1783 Epsilon: 0.8351\n",
      "Episode: 90 Total reward: 12.0 Training loss: 67.7187 Epsilon: 0.8341\n",
      "Episode: 91 Total reward: 12.0 Training loss: 7.4581 Epsilon: 0.8331\n",
      "Episode: 92 Total reward: 12.0 Training loss: 7.6304 Epsilon: 0.8321\n",
      "Episode: 93 Total reward: 15.0 Training loss: 130.1133 Epsilon: 0.8309\n",
      "Episode: 94 Total reward: 8.0 Training loss: 36.2361 Epsilon: 0.8302\n",
      "Episode: 95 Total reward: 16.0 Training loss: 9.0090 Epsilon: 0.8289\n",
      "Episode: 96 Total reward: 12.0 Training loss: 72.8331 Epsilon: 0.8280\n",
      "Episode: 97 Total reward: 12.0 Training loss: 10.7935 Epsilon: 0.8270\n",
      "Episode: 98 Total reward: 11.0 Training loss: 75.7925 Epsilon: 0.8261\n",
      "Episode: 99 Total reward: 12.0 Training loss: 41.9669 Epsilon: 0.8251\n",
      "Episode: 100 Total reward: 15.0 Training loss: 45.2106 Epsilon: 0.8239\n",
      "Episode: 101 Total reward: 11.0 Training loss: 9.6444 Epsilon: 0.8230\n",
      "Episode: 102 Total reward: 13.0 Training loss: 52.3458 Epsilon: 0.8219\n",
      "Episode: 103 Total reward: 12.0 Training loss: 8.9157 Epsilon: 0.8209\n",
      "Episode: 104 Total reward: 18.0 Training loss: 59.6426 Epsilon: 0.8195\n",
      "Episode: 105 Total reward: 42.0 Training loss: 122.7039 Epsilon: 0.8161\n",
      "Episode: 106 Total reward: 10.0 Training loss: 81.6488 Epsilon: 0.8153\n",
      "Episode: 107 Total reward: 18.0 Training loss: 100.3327 Epsilon: 0.8138\n",
      "Episode: 108 Total reward: 25.0 Training loss: 38.5768 Epsilon: 0.8118\n",
      "Episode: 109 Total reward: 19.0 Training loss: 43.7752 Epsilon: 0.8103\n",
      "Episode: 110 Total reward: 36.0 Training loss: 91.3198 Epsilon: 0.8074\n",
      "Episode: 111 Total reward: 12.0 Training loss: 44.9329 Epsilon: 0.8065\n",
      "Episode: 112 Total reward: 17.0 Training loss: 56.5086 Epsilon: 0.8051\n",
      "Episode: 113 Total reward: 29.0 Training loss: 9.8514 Epsilon: 0.8028\n",
      "Episode: 114 Total reward: 11.0 Training loss: 67.7516 Epsilon: 0.8020\n",
      "Episode: 115 Total reward: 15.0 Training loss: 181.2635 Epsilon: 0.8008\n",
      "Episode: 116 Total reward: 22.0 Training loss: 129.6825 Epsilon: 0.7990\n",
      "Episode: 117 Total reward: 28.0 Training loss: 155.0041 Epsilon: 0.7968\n",
      "Episode: 118 Total reward: 9.0 Training loss: 115.4032 Epsilon: 0.7961\n",
      "Episode: 119 Total reward: 23.0 Training loss: 54.0160 Epsilon: 0.7943\n",
      "Episode: 120 Total reward: 20.0 Training loss: 329.7549 Epsilon: 0.7927\n",
      "Episode: 121 Total reward: 13.0 Training loss: 7.3812 Epsilon: 0.7917\n",
      "Episode: 122 Total reward: 10.0 Training loss: 52.9793 Epsilon: 0.7909\n",
      "Episode: 123 Total reward: 9.0 Training loss: 108.5515 Epsilon: 0.7902\n",
      "Episode: 124 Total reward: 27.0 Training loss: 6.3303 Epsilon: 0.7881\n",
      "Episode: 125 Total reward: 12.0 Training loss: 8.1145 Epsilon: 0.7872\n",
      "Episode: 126 Total reward: 12.0 Training loss: 6.9049 Epsilon: 0.7863\n",
      "Episode: 127 Total reward: 13.0 Training loss: 6.7238 Epsilon: 0.7853\n",
      "Episode: 128 Total reward: 13.0 Training loss: 92.0029 Epsilon: 0.7843\n",
      "Episode: 129 Total reward: 17.0 Training loss: 6.5273 Epsilon: 0.7829\n",
      "Episode: 130 Total reward: 11.0 Training loss: 129.3844 Epsilon: 0.7821\n",
      "Episode: 131 Total reward: 8.0 Training loss: 190.4696 Epsilon: 0.7815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 132 Total reward: 10.0 Training loss: 234.3138 Epsilon: 0.7807\n",
      "Episode: 133 Total reward: 17.0 Training loss: 65.8640 Epsilon: 0.7794\n",
      "Episode: 134 Total reward: 16.0 Training loss: 4.8000 Epsilon: 0.7782\n",
      "Episode: 135 Total reward: 7.0 Training loss: 76.0896 Epsilon: 0.7776\n",
      "Episode: 136 Total reward: 22.0 Training loss: 67.2840 Epsilon: 0.7759\n",
      "Episode: 137 Total reward: 12.0 Training loss: 137.0765 Epsilon: 0.7750\n",
      "Episode: 138 Total reward: 8.0 Training loss: 105.0211 Epsilon: 0.7744\n",
      "Episode: 139 Total reward: 29.0 Training loss: 4.9385 Epsilon: 0.7722\n",
      "Episode: 140 Total reward: 48.0 Training loss: 141.5664 Epsilon: 0.7685\n",
      "Episode: 141 Total reward: 13.0 Training loss: 4.6600 Epsilon: 0.7676\n",
      "Episode: 142 Total reward: 45.0 Training loss: 125.7756 Epsilon: 0.7642\n",
      "Episode: 143 Total reward: 13.0 Training loss: 96.9360 Epsilon: 0.7632\n",
      "Episode: 144 Total reward: 23.0 Training loss: 205.0935 Epsilon: 0.7615\n",
      "Episode: 145 Total reward: 16.0 Training loss: 3.9069 Epsilon: 0.7602\n",
      "Episode: 146 Total reward: 18.0 Training loss: 64.4306 Epsilon: 0.7589\n",
      "Episode: 147 Total reward: 23.0 Training loss: 90.2409 Epsilon: 0.7572\n",
      "Episode: 148 Total reward: 8.0 Training loss: 82.0201 Epsilon: 0.7566\n",
      "Episode: 149 Total reward: 11.0 Training loss: 71.3683 Epsilon: 0.7558\n",
      "Episode: 150 Total reward: 13.0 Training loss: 126.3956 Epsilon: 0.7548\n",
      "Episode: 151 Total reward: 43.0 Training loss: 60.4266 Epsilon: 0.7516\n",
      "Episode: 152 Total reward: 28.0 Training loss: 3.6376 Epsilon: 0.7495\n",
      "Episode: 153 Total reward: 13.0 Training loss: 140.8887 Epsilon: 0.7486\n",
      "Episode: 154 Total reward: 22.0 Training loss: 210.3889 Epsilon: 0.7469\n",
      "Episode: 155 Total reward: 7.0 Training loss: 3.1487 Epsilon: 0.7464\n",
      "Episode: 156 Total reward: 28.0 Training loss: 63.4426 Epsilon: 0.7444\n",
      "Episode: 157 Total reward: 19.0 Training loss: 102.5162 Epsilon: 0.7430\n",
      "Episode: 158 Total reward: 8.0 Training loss: 62.0983 Epsilon: 0.7424\n",
      "Episode: 159 Total reward: 14.0 Training loss: 57.1117 Epsilon: 0.7414\n",
      "Episode: 160 Total reward: 11.0 Training loss: 67.9018 Epsilon: 0.7406\n",
      "Episode: 161 Total reward: 28.0 Training loss: 71.4653 Epsilon: 0.7385\n",
      "Episode: 162 Total reward: 14.0 Training loss: 2.0264 Epsilon: 0.7375\n",
      "Episode: 163 Total reward: 19.0 Training loss: 60.4877 Epsilon: 0.7361\n",
      "Episode: 164 Total reward: 11.0 Training loss: 63.3362 Epsilon: 0.7353\n",
      "Episode: 165 Total reward: 10.0 Training loss: 112.9175 Epsilon: 0.7346\n",
      "Episode: 166 Total reward: 15.0 Training loss: 149.3251 Epsilon: 0.7335\n",
      "Episode: 167 Total reward: 18.0 Training loss: 75.9800 Epsilon: 0.7322\n",
      "Episode: 168 Total reward: 11.0 Training loss: 58.0616 Epsilon: 0.7314\n",
      "Episode: 169 Total reward: 16.0 Training loss: 1.8607 Epsilon: 0.7303\n",
      "Episode: 170 Total reward: 15.0 Training loss: 1.5358 Epsilon: 0.7292\n",
      "Episode: 171 Total reward: 13.0 Training loss: 1.6645 Epsilon: 0.7282\n",
      "Episode: 172 Total reward: 11.0 Training loss: 1.7780 Epsilon: 0.7275\n",
      "Episode: 173 Total reward: 17.0 Training loss: 1.5500 Epsilon: 0.7262\n",
      "Episode: 174 Total reward: 16.0 Training loss: 98.4800 Epsilon: 0.7251\n",
      "Episode: 175 Total reward: 16.0 Training loss: 75.2496 Epsilon: 0.7239\n",
      "Episode: 176 Total reward: 19.0 Training loss: 162.3439 Epsilon: 0.7226\n",
      "Episode: 177 Total reward: 24.0 Training loss: 1.5415 Epsilon: 0.7209\n",
      "Episode: 178 Total reward: 9.0 Training loss: 2.1998 Epsilon: 0.7202\n",
      "Episode: 179 Total reward: 22.0 Training loss: 170.5654 Epsilon: 0.7187\n",
      "Episode: 180 Total reward: 12.0 Training loss: 1.5009 Epsilon: 0.7178\n",
      "Episode: 181 Total reward: 12.0 Training loss: 87.7732 Epsilon: 0.7170\n",
      "Episode: 182 Total reward: 12.0 Training loss: 1.6434 Epsilon: 0.7161\n",
      "Episode: 183 Total reward: 14.0 Training loss: 2.1279 Epsilon: 0.7151\n",
      "Episode: 184 Total reward: 10.0 Training loss: 39.9771 Epsilon: 0.7144\n",
      "Episode: 185 Total reward: 32.0 Training loss: 1.4348 Epsilon: 0.7122\n",
      "Episode: 186 Total reward: 10.0 Training loss: 98.4195 Epsilon: 0.7115\n",
      "Episode: 187 Total reward: 23.0 Training loss: 1.3428 Epsilon: 0.7099\n",
      "Episode: 188 Total reward: 24.0 Training loss: 37.1081 Epsilon: 0.7082\n",
      "Episode: 189 Total reward: 16.0 Training loss: 1.2178 Epsilon: 0.7071\n",
      "Episode: 190 Total reward: 34.0 Training loss: 1.4350 Epsilon: 0.7047\n",
      "Episode: 191 Total reward: 12.0 Training loss: 1.0124 Epsilon: 0.7039\n",
      "Episode: 192 Total reward: 7.0 Training loss: 0.9992 Epsilon: 0.7034\n",
      "Episode: 193 Total reward: 10.0 Training loss: 45.2028 Epsilon: 0.7027\n",
      "Episode: 194 Total reward: 18.0 Training loss: 32.5169 Epsilon: 0.7015\n",
      "Episode: 195 Total reward: 12.0 Training loss: 67.2842 Epsilon: 0.7006\n",
      "Episode: 196 Total reward: 12.0 Training loss: 31.9696 Epsilon: 0.6998\n",
      "Episode: 197 Total reward: 10.0 Training loss: 2.3845 Epsilon: 0.6991\n",
      "Episode: 198 Total reward: 8.0 Training loss: 53.5230 Epsilon: 0.6986\n",
      "Episode: 199 Total reward: 9.0 Training loss: 33.5465 Epsilon: 0.6979\n",
      "Episode: 200 Total reward: 18.0 Training loss: 1.6439 Epsilon: 0.6967\n",
      "Episode: 201 Total reward: 20.0 Training loss: 78.5441 Epsilon: 0.6953\n",
      "Episode: 202 Total reward: 17.0 Training loss: 59.4619 Epsilon: 0.6942\n",
      "Episode: 203 Total reward: 16.0 Training loss: 43.7387 Epsilon: 0.6931\n",
      "Episode: 204 Total reward: 37.0 Training loss: 28.8312 Epsilon: 0.6906\n",
      "Episode: 205 Total reward: 10.0 Training loss: 69.9082 Epsilon: 0.6899\n",
      "Episode: 206 Total reward: 19.0 Training loss: 1.5843 Epsilon: 0.6886\n",
      "Episode: 207 Total reward: 11.0 Training loss: 1.0353 Epsilon: 0.6878\n",
      "Episode: 208 Total reward: 14.0 Training loss: 43.9191 Epsilon: 0.6869\n",
      "Episode: 209 Total reward: 10.0 Training loss: 0.9212 Epsilon: 0.6862\n",
      "Episode: 210 Total reward: 24.0 Training loss: 26.9233 Epsilon: 0.6846\n",
      "Episode: 211 Total reward: 16.0 Training loss: 43.9857 Epsilon: 0.6835\n",
      "Episode: 212 Total reward: 21.0 Training loss: 90.7646 Epsilon: 0.6821\n",
      "Episode: 213 Total reward: 28.0 Training loss: 47.7519 Epsilon: 0.6802\n",
      "Episode: 214 Total reward: 24.0 Training loss: 52.5085 Epsilon: 0.6786\n",
      "Episode: 215 Total reward: 8.0 Training loss: 23.7520 Epsilon: 0.6781\n",
      "Episode: 216 Total reward: 21.0 Training loss: 1.7617 Epsilon: 0.6767\n",
      "Episode: 217 Total reward: 13.0 Training loss: 22.4700 Epsilon: 0.6758\n",
      "Episode: 218 Total reward: 9.0 Training loss: 1.4339 Epsilon: 0.6752\n",
      "Episode: 219 Total reward: 11.0 Training loss: 23.5649 Epsilon: 0.6745\n",
      "Episode: 220 Total reward: 15.0 Training loss: 24.5075 Epsilon: 0.6735\n",
      "Episode: 221 Total reward: 13.0 Training loss: 42.4517 Epsilon: 0.6726\n",
      "Episode: 222 Total reward: 30.0 Training loss: 81.2829 Epsilon: 0.6706\n",
      "Episode: 223 Total reward: 12.0 Training loss: 1.8287 Epsilon: 0.6698\n",
      "Episode: 224 Total reward: 12.0 Training loss: 91.7088 Epsilon: 0.6691\n",
      "Episode: 225 Total reward: 11.0 Training loss: 21.4422 Epsilon: 0.6683\n",
      "Episode: 226 Total reward: 12.0 Training loss: 1.7733 Epsilon: 0.6675\n",
      "Episode: 227 Total reward: 13.0 Training loss: 97.5667 Epsilon: 0.6667\n",
      "Episode: 228 Total reward: 10.0 Training loss: 1.7771 Epsilon: 0.6660\n",
      "Episode: 229 Total reward: 11.0 Training loss: 76.9122 Epsilon: 0.6653\n",
      "Episode: 230 Total reward: 19.0 Training loss: 39.8338 Epsilon: 0.6641\n",
      "Episode: 231 Total reward: 15.0 Training loss: 20.6204 Epsilon: 0.6631\n",
      "Episode: 232 Total reward: 12.0 Training loss: 55.5461 Epsilon: 0.6623\n",
      "Episode: 233 Total reward: 10.0 Training loss: 37.2180 Epsilon: 0.6616\n",
      "Episode: 234 Total reward: 12.0 Training loss: 47.0341 Epsilon: 0.6609\n",
      "Episode: 235 Total reward: 14.0 Training loss: 2.5595 Epsilon: 0.6600\n",
      "Episode: 236 Total reward: 12.0 Training loss: 19.3580 Epsilon: 0.6592\n",
      "Episode: 237 Total reward: 15.0 Training loss: 2.2156 Epsilon: 0.6582\n",
      "Episode: 238 Total reward: 41.0 Training loss: 1.4781 Epsilon: 0.6556\n",
      "Episode: 239 Total reward: 26.0 Training loss: 1.4818 Epsilon: 0.6539\n",
      "Episode: 240 Total reward: 23.0 Training loss: 38.9851 Epsilon: 0.6524\n",
      "Episode: 241 Total reward: 37.0 Training loss: 41.7592 Epsilon: 0.6500\n",
      "Episode: 242 Total reward: 9.0 Training loss: 52.8980 Epsilon: 0.6494\n",
      "Episode: 243 Total reward: 12.0 Training loss: 18.5222 Epsilon: 0.6487\n",
      "Episode: 244 Total reward: 13.0 Training loss: 51.0891 Epsilon: 0.6479\n",
      "Episode: 245 Total reward: 14.0 Training loss: 17.3371 Epsilon: 0.6470\n",
      "Episode: 246 Total reward: 13.0 Training loss: 34.0875 Epsilon: 0.6461\n",
      "Episode: 247 Total reward: 19.0 Training loss: 36.4048 Epsilon: 0.6449\n",
      "Episode: 248 Total reward: 12.0 Training loss: 1.9641 Epsilon: 0.6442\n",
      "Episode: 249 Total reward: 14.0 Training loss: 1.7672 Epsilon: 0.6433\n",
      "Episode: 250 Total reward: 10.0 Training loss: 31.3768 Epsilon: 0.6426\n",
      "Episode: 251 Total reward: 13.0 Training loss: 32.4945 Epsilon: 0.6418\n",
      "Episode: 252 Total reward: 11.0 Training loss: 2.0063 Epsilon: 0.6411\n",
      "Episode: 253 Total reward: 10.0 Training loss: 45.7780 Epsilon: 0.6405\n",
      "Episode: 254 Total reward: 12.0 Training loss: 56.4001 Epsilon: 0.6397\n",
      "Episode: 255 Total reward: 10.0 Training loss: 22.2417 Epsilon: 0.6391\n",
      "Episode: 256 Total reward: 14.0 Training loss: 74.6194 Epsilon: 0.6382\n",
      "Episode: 257 Total reward: 8.0 Training loss: 56.4553 Epsilon: 0.6377\n",
      "Episode: 258 Total reward: 11.0 Training loss: 46.7973 Epsilon: 0.6370\n",
      "Episode: 259 Total reward: 8.0 Training loss: 41.8920 Epsilon: 0.6365\n",
      "Episode: 260 Total reward: 25.0 Training loss: 18.4064 Epsilon: 0.6350\n",
      "Episode: 261 Total reward: 16.0 Training loss: 1.7211 Epsilon: 0.6340\n",
      "Episode: 262 Total reward: 20.0 Training loss: 2.0639 Epsilon: 0.6327\n",
      "Episode: 263 Total reward: 16.0 Training loss: 25.1326 Epsilon: 0.6317\n",
      "Episode: 264 Total reward: 12.0 Training loss: 2.3822 Epsilon: 0.6310\n",
      "Episode: 265 Total reward: 15.0 Training loss: 75.5339 Epsilon: 0.6301\n",
      "Episode: 266 Total reward: 9.0 Training loss: 1.4055 Epsilon: 0.6295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 267 Total reward: 9.0 Training loss: 1.7540 Epsilon: 0.6289\n",
      "Episode: 268 Total reward: 9.0 Training loss: 19.6852 Epsilon: 0.6284\n",
      "Episode: 269 Total reward: 18.0 Training loss: 46.4078 Epsilon: 0.6273\n",
      "Episode: 270 Total reward: 14.0 Training loss: 59.7192 Epsilon: 0.6264\n",
      "Episode: 271 Total reward: 7.0 Training loss: 16.4538 Epsilon: 0.6260\n",
      "Episode: 272 Total reward: 12.0 Training loss: 34.7354 Epsilon: 0.6252\n",
      "Episode: 273 Total reward: 15.0 Training loss: 1.9164 Epsilon: 0.6243\n",
      "Episode: 274 Total reward: 10.0 Training loss: 105.1852 Epsilon: 0.6237\n",
      "Episode: 275 Total reward: 18.0 Training loss: 58.6560 Epsilon: 0.6226\n",
      "Episode: 276 Total reward: 25.0 Training loss: 35.2930 Epsilon: 0.6211\n",
      "Episode: 277 Total reward: 20.0 Training loss: 25.6033 Epsilon: 0.6198\n",
      "Episode: 278 Total reward: 16.0 Training loss: 1.2940 Epsilon: 0.6189\n",
      "Episode: 279 Total reward: 19.0 Training loss: 1.7307 Epsilon: 0.6177\n",
      "Episode: 280 Total reward: 9.0 Training loss: 59.9218 Epsilon: 0.6172\n",
      "Episode: 281 Total reward: 11.0 Training loss: 1.4968 Epsilon: 0.6165\n",
      "Episode: 282 Total reward: 15.0 Training loss: 1.5015 Epsilon: 0.6156\n",
      "Episode: 283 Total reward: 20.0 Training loss: 16.3474 Epsilon: 0.6144\n",
      "Episode: 284 Total reward: 31.0 Training loss: 44.8355 Epsilon: 0.6125\n",
      "Episode: 285 Total reward: 15.0 Training loss: 30.1144 Epsilon: 0.6116\n",
      "Episode: 286 Total reward: 14.0 Training loss: 41.5982 Epsilon: 0.6108\n",
      "Episode: 287 Total reward: 18.0 Training loss: 38.2950 Epsilon: 0.6097\n",
      "Episode: 288 Total reward: 12.0 Training loss: 69.4104 Epsilon: 0.6090\n",
      "Episode: 289 Total reward: 10.0 Training loss: 33.9415 Epsilon: 0.6084\n",
      "Episode: 290 Total reward: 13.0 Training loss: 39.8035 Epsilon: 0.6076\n",
      "Episode: 291 Total reward: 15.0 Training loss: 30.8635 Epsilon: 0.6067\n",
      "Episode: 292 Total reward: 9.0 Training loss: 64.3089 Epsilon: 0.6062\n",
      "Episode: 293 Total reward: 17.0 Training loss: 1.2507 Epsilon: 0.6051\n",
      "Episode: 294 Total reward: 18.0 Training loss: 1.4621 Epsilon: 0.6041\n",
      "Episode: 295 Total reward: 17.0 Training loss: 29.8339 Epsilon: 0.6031\n",
      "Episode: 296 Total reward: 8.0 Training loss: 1.3075 Epsilon: 0.6026\n",
      "Episode: 297 Total reward: 8.0 Training loss: 28.5988 Epsilon: 0.6021\n",
      "Episode: 298 Total reward: 14.0 Training loss: 1.4366 Epsilon: 0.6013\n",
      "Episode: 299 Total reward: 53.0 Training loss: 40.2016 Epsilon: 0.5982\n",
      "Episode: 300 Total reward: 15.0 Training loss: 0.9761 Epsilon: 0.5973\n",
      "Episode: 301 Total reward: 9.0 Training loss: 17.7129 Epsilon: 0.5968\n",
      "Episode: 302 Total reward: 25.0 Training loss: 1.3221 Epsilon: 0.5953\n",
      "Episode: 303 Total reward: 19.0 Training loss: 1.1221 Epsilon: 0.5942\n",
      "Episode: 304 Total reward: 18.0 Training loss: 69.0058 Epsilon: 0.5931\n",
      "Episode: 305 Total reward: 21.0 Training loss: 25.3403 Epsilon: 0.5919\n",
      "Episode: 306 Total reward: 40.0 Training loss: 46.2391 Epsilon: 0.5896\n",
      "Episode: 307 Total reward: 86.0 Training loss: 70.1624 Epsilon: 0.5846\n",
      "Episode: 308 Total reward: 47.0 Training loss: 1.0291 Epsilon: 0.5819\n",
      "Episode: 309 Total reward: 38.0 Training loss: 0.9633 Epsilon: 0.5798\n",
      "Episode: 310 Total reward: 54.0 Training loss: 55.0404 Epsilon: 0.5767\n",
      "Episode: 311 Total reward: 27.0 Training loss: 0.7882 Epsilon: 0.5752\n",
      "Episode: 312 Total reward: 30.0 Training loss: 20.4408 Epsilon: 0.5735\n",
      "Episode: 313 Total reward: 89.0 Training loss: 0.8781 Epsilon: 0.5685\n",
      "Episode: 314 Total reward: 24.0 Training loss: 56.0028 Epsilon: 0.5671\n",
      "Episode: 315 Total reward: 99.0 Training loss: 0.9787 Epsilon: 0.5616\n",
      "Episode: 316 Total reward: 51.0 Training loss: 33.0993 Epsilon: 0.5588\n",
      "Episode: 317 Total reward: 61.0 Training loss: 16.9713 Epsilon: 0.5555\n",
      "Episode: 318 Total reward: 184.0 Training loss: 16.0804 Epsilon: 0.5456\n",
      "Episode: 319 Total reward: 31.0 Training loss: 26.6427 Epsilon: 0.5439\n",
      "Episode: 320 Total reward: 116.0 Training loss: 15.0961 Epsilon: 0.5377\n",
      "Episode: 321 Total reward: 34.0 Training loss: 27.5470 Epsilon: 0.5359\n",
      "Episode: 322 Total reward: 112.0 Training loss: 0.9240 Epsilon: 0.5301\n",
      "Episode: 323 Total reward: 40.0 Training loss: 15.8625 Epsilon: 0.5280\n",
      "Episode: 324 Total reward: 40.0 Training loss: 13.4028 Epsilon: 0.5259\n",
      "Episode: 325 Total reward: 58.0 Training loss: 16.1495 Epsilon: 0.5230\n",
      "Episode: 326 Total reward: 32.0 Training loss: 23.2154 Epsilon: 0.5213\n",
      "Episode: 327 Total reward: 28.0 Training loss: 15.5850 Epsilon: 0.5199\n",
      "Episode: 328 Total reward: 75.0 Training loss: 16.8980 Epsilon: 0.5161\n",
      "Episode: 329 Total reward: 68.0 Training loss: 15.2984 Epsilon: 0.5127\n",
      "Episode: 330 Total reward: 63.0 Training loss: 16.1195 Epsilon: 0.5095\n",
      "Episode: 331 Total reward: 12.0 Training loss: 1.1961 Epsilon: 0.5089\n",
      "Episode: 332 Total reward: 78.0 Training loss: 44.3082 Epsilon: 0.5050\n",
      "Episode: 333 Total reward: 77.0 Training loss: 1.4645 Epsilon: 0.5012\n",
      "Episode: 334 Total reward: 25.0 Training loss: 1.1463 Epsilon: 0.5000\n",
      "Episode: 335 Total reward: 26.0 Training loss: 12.4424 Epsilon: 0.4987\n",
      "Episode: 336 Total reward: 30.0 Training loss: 18.7858 Epsilon: 0.4973\n",
      "Episode: 337 Total reward: 33.0 Training loss: 13.2395 Epsilon: 0.4957\n",
      "Episode: 338 Total reward: 33.0 Training loss: 1.3041 Epsilon: 0.4941\n",
      "Episode: 339 Total reward: 18.0 Training loss: 33.5772 Epsilon: 0.4932\n",
      "Episode: 340 Total reward: 28.0 Training loss: 1.2359 Epsilon: 0.4918\n",
      "Episode: 341 Total reward: 30.0 Training loss: 46.0791 Epsilon: 0.4904\n",
      "Episode: 342 Total reward: 37.0 Training loss: 1.1423 Epsilon: 0.4886\n",
      "Episode: 343 Total reward: 28.0 Training loss: 21.3349 Epsilon: 0.4873\n",
      "Episode: 344 Total reward: 40.0 Training loss: 1.0124 Epsilon: 0.4854\n",
      "Episode: 345 Total reward: 46.0 Training loss: 1.4029 Epsilon: 0.4832\n",
      "Episode: 346 Total reward: 21.0 Training loss: 39.1837 Epsilon: 0.4822\n",
      "Episode: 347 Total reward: 39.0 Training loss: 1.1089 Epsilon: 0.4804\n",
      "Episode: 348 Total reward: 14.0 Training loss: 20.0541 Epsilon: 0.4797\n",
      "Episode: 349 Total reward: 39.0 Training loss: 72.9051 Epsilon: 0.4779\n",
      "Episode: 350 Total reward: 47.0 Training loss: 20.6177 Epsilon: 0.4757\n",
      "Episode: 351 Total reward: 46.0 Training loss: 35.2908 Epsilon: 0.4735\n",
      "Episode: 352 Total reward: 35.0 Training loss: 14.8765 Epsilon: 0.4719\n",
      "Episode: 353 Total reward: 20.0 Training loss: 35.5646 Epsilon: 0.4710\n",
      "Episode: 354 Total reward: 48.0 Training loss: 1.0597 Epsilon: 0.4688\n",
      "Episode: 355 Total reward: 13.0 Training loss: 0.7379 Epsilon: 0.4682\n",
      "Episode: 356 Total reward: 43.0 Training loss: 59.3554 Epsilon: 0.4662\n",
      "Episode: 357 Total reward: 85.0 Training loss: 21.5519 Epsilon: 0.4624\n",
      "Episode: 358 Total reward: 50.0 Training loss: 1.5365 Epsilon: 0.4601\n",
      "Episode: 359 Total reward: 130.0 Training loss: 1.5273 Epsilon: 0.4543\n",
      "Episode: 360 Total reward: 65.0 Training loss: 21.8144 Epsilon: 0.4514\n",
      "Episode: 361 Total reward: 33.0 Training loss: 24.7204 Epsilon: 0.4500\n",
      "Episode: 362 Total reward: 86.0 Training loss: 38.7015 Epsilon: 0.4462\n",
      "Episode: 363 Total reward: 41.0 Training loss: 62.1250 Epsilon: 0.4444\n",
      "Episode: 364 Total reward: 90.0 Training loss: 1.3419 Epsilon: 0.4405\n",
      "Episode: 365 Total reward: 117.0 Training loss: 37.1612 Epsilon: 0.4355\n",
      "Episode: 366 Total reward: 78.0 Training loss: 67.8300 Epsilon: 0.4322\n",
      "Episode: 367 Total reward: 103.0 Training loss: 2.3687 Epsilon: 0.4279\n",
      "Episode: 368 Total reward: 53.0 Training loss: 0.9566 Epsilon: 0.4257\n",
      "Episode: 369 Total reward: 17.0 Training loss: 27.7983 Epsilon: 0.4250\n",
      "Episode: 370 Total reward: 74.0 Training loss: 1.1885 Epsilon: 0.4219\n",
      "Episode: 371 Total reward: 152.0 Training loss: 27.0926 Epsilon: 0.4157\n",
      "Episode: 372 Total reward: 160.0 Training loss: 1.3479 Epsilon: 0.4093\n",
      "Episode: 373 Total reward: 70.0 Training loss: 1.3156 Epsilon: 0.4065\n",
      "Episode: 374 Total reward: 93.0 Training loss: 23.9211 Epsilon: 0.4028\n",
      "Episode: 375 Total reward: 98.0 Training loss: 39.2940 Epsilon: 0.3990\n",
      "Episode: 376 Total reward: 171.0 Training loss: 24.4913 Epsilon: 0.3924\n",
      "Episode: 377 Total reward: 107.0 Training loss: 30.8024 Epsilon: 0.3883\n",
      "Episode: 378 Total reward: 29.0 Training loss: 31.1935 Epsilon: 0.3872\n",
      "Episode: 379 Total reward: 51.0 Training loss: 0.9982 Epsilon: 0.3853\n",
      "Episode: 380 Total reward: 120.0 Training loss: 28.5359 Epsilon: 0.3808\n",
      "Episode: 381 Total reward: 47.0 Training loss: 1.2958 Epsilon: 0.3791\n",
      "Episode: 382 Total reward: 71.0 Training loss: 1.8346 Epsilon: 0.3765\n",
      "Episode: 383 Total reward: 56.0 Training loss: 2.3429 Epsilon: 0.3744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 384 Total reward: 70.0 Training loss: 17.3016 Epsilon: 0.3719\n",
      "Episode: 385 Total reward: 47.0 Training loss: 22.6296 Epsilon: 0.3702\n",
      "Episode: 386 Total reward: 50.0 Training loss: 0.7775 Epsilon: 0.3684\n",
      "Episode: 387 Total reward: 28.0 Training loss: 1.3259 Epsilon: 0.3674\n",
      "Episode: 388 Total reward: 45.0 Training loss: 1.4220 Epsilon: 0.3658\n",
      "Episode: 389 Total reward: 74.0 Training loss: 0.7588 Epsilon: 0.3632\n",
      "Episode: 390 Total reward: 101.0 Training loss: 20.6088 Epsilon: 0.3596\n",
      "Episode: 391 Total reward: 77.0 Training loss: 21.9845 Epsilon: 0.3569\n",
      "Episode: 392 Total reward: 185.0 Training loss: 37.4617 Epsilon: 0.3506\n",
      "Episode: 393 Total reward: 192.0 Training loss: 48.4974 Epsilon: 0.3441\n",
      "Episode: 394 Total reward: 71.0 Training loss: 33.0499 Epsilon: 0.3417\n",
      "Episode: 395 Total reward: 55.0 Training loss: 49.3607 Epsilon: 0.3399\n",
      "Episode: 396 Total reward: 51.0 Training loss: 33.1060 Epsilon: 0.3382\n",
      "Episode: 397 Total reward: 50.0 Training loss: 2.0712 Epsilon: 0.3366\n",
      "Episode: 398 Total reward: 80.0 Training loss: 37.8831 Epsilon: 0.3340\n",
      "Episode: 399 Total reward: 152.0 Training loss: 13.2038 Epsilon: 0.3291\n",
      "Episode: 400 Total reward: 79.0 Training loss: 15.2732 Epsilon: 0.3266\n",
      "Episode: 401 Total reward: 28.0 Training loss: 36.6674 Epsilon: 0.3257\n",
      "Episode: 402 Total reward: 59.0 Training loss: 1.0310 Epsilon: 0.3238\n",
      "Episode: 403 Total reward: 113.0 Training loss: 1.0694 Epsilon: 0.3203\n",
      "Episode: 404 Total reward: 75.0 Training loss: 70.0285 Epsilon: 0.3180\n",
      "Episode: 405 Total reward: 13.0 Training loss: 48.7623 Epsilon: 0.3176\n",
      "Episode: 406 Total reward: 96.0 Training loss: 1.7463 Epsilon: 0.3147\n",
      "Episode: 407 Total reward: 39.0 Training loss: 16.9402 Epsilon: 0.3135\n",
      "Episode: 408 Total reward: 41.0 Training loss: 179.9224 Epsilon: 0.3122\n",
      "Episode: 409 Total reward: 59.0 Training loss: 2.4297 Epsilon: 0.3105\n",
      "Episode: 410 Total reward: 70.0 Training loss: 2.8378 Epsilon: 0.3084\n",
      "Episode: 411 Total reward: 63.0 Training loss: 1.7237 Epsilon: 0.3065\n",
      "Episode: 412 Total reward: 71.0 Training loss: 41.7200 Epsilon: 0.3044\n",
      "Episode: 413 Total reward: 55.0 Training loss: 2.0682 Epsilon: 0.3028\n",
      "Episode: 414 Total reward: 45.0 Training loss: 46.8646 Epsilon: 0.3015\n",
      "Episode: 415 Total reward: 86.0 Training loss: 1.2151 Epsilon: 0.2990\n",
      "Episode: 416 Total reward: 134.0 Training loss: 47.3103 Epsilon: 0.2951\n",
      "Episode: 417 Total reward: 99.0 Training loss: 2.5332 Epsilon: 0.2923\n",
      "Episode: 418 Total reward: 38.0 Training loss: 2.3485 Epsilon: 0.2912\n",
      "Episode: 419 Total reward: 50.0 Training loss: 131.7600 Epsilon: 0.2898\n",
      "Episode: 420 Total reward: 61.0 Training loss: 0.8912 Epsilon: 0.2881\n",
      "Episode: 421 Total reward: 43.0 Training loss: 1.7788 Epsilon: 0.2869\n",
      "Episode: 422 Total reward: 69.0 Training loss: 44.7406 Epsilon: 0.2850\n",
      "Episode: 423 Total reward: 62.0 Training loss: 3.5813 Epsilon: 0.2833\n",
      "Episode: 424 Total reward: 39.0 Training loss: 1.3637 Epsilon: 0.2823\n",
      "Episode: 425 Total reward: 52.0 Training loss: 1.8980 Epsilon: 0.2809\n",
      "Episode: 426 Total reward: 56.0 Training loss: 41.8186 Epsilon: 0.2793\n",
      "Episode: 427 Total reward: 95.0 Training loss: 1.9513 Epsilon: 0.2768\n",
      "Episode: 428 Total reward: 36.0 Training loss: 1.0565 Epsilon: 0.2758\n",
      "Episode: 429 Total reward: 52.0 Training loss: 2.7054 Epsilon: 0.2745\n",
      "Episode: 430 Total reward: 49.0 Training loss: 2.2546 Epsilon: 0.2732\n",
      "Episode: 431 Total reward: 157.0 Training loss: 0.8968 Epsilon: 0.2691\n",
      "Episode: 432 Total reward: 58.0 Training loss: 1.4090 Epsilon: 0.2676\n",
      "Episode: 433 Total reward: 63.0 Training loss: 36.3087 Epsilon: 0.2660\n",
      "Episode: 434 Total reward: 191.0 Training loss: 2.4043 Epsilon: 0.2611\n",
      "Episode: 435 Total reward: 64.0 Training loss: 2.3902 Epsilon: 0.2595\n",
      "Episode: 436 Total reward: 70.0 Training loss: 50.0763 Epsilon: 0.2578\n",
      "Episode: 437 Total reward: 93.0 Training loss: 1.8985 Epsilon: 0.2555\n",
      "Episode: 438 Total reward: 28.0 Training loss: 0.7622 Epsilon: 0.2548\n",
      "Episode: 439 Total reward: 43.0 Training loss: 11.0292 Epsilon: 0.2537\n",
      "Episode: 440 Total reward: 52.0 Training loss: 0.8258 Epsilon: 0.2525\n",
      "Episode: 441 Total reward: 100.0 Training loss: 1.9180 Epsilon: 0.2501\n",
      "Episode: 442 Total reward: 39.0 Training loss: 59.2303 Epsilon: 0.2491\n",
      "Episode: 443 Total reward: 33.0 Training loss: 63.4539 Epsilon: 0.2483\n",
      "Episode: 444 Total reward: 33.0 Training loss: 56.5605 Epsilon: 0.2476\n",
      "Episode: 445 Total reward: 72.0 Training loss: 1.4044 Epsilon: 0.2459\n",
      "Episode: 446 Total reward: 64.0 Training loss: 1.9183 Epsilon: 0.2443\n",
      "Episode: 447 Total reward: 50.0 Training loss: 69.9286 Epsilon: 0.2432\n",
      "Episode: 448 Total reward: 57.0 Training loss: 0.7204 Epsilon: 0.2419\n",
      "Episode: 449 Total reward: 37.0 Training loss: 1.1483 Epsilon: 0.2410\n",
      "Episode: 450 Total reward: 30.0 Training loss: 0.9460 Epsilon: 0.2403\n",
      "Episode: 451 Total reward: 73.0 Training loss: 1.5268 Epsilon: 0.2386\n",
      "Episode: 452 Total reward: 55.0 Training loss: 1.9803 Epsilon: 0.2374\n",
      "Episode: 453 Total reward: 64.0 Training loss: 1.0149 Epsilon: 0.2359\n",
      "Episode: 454 Total reward: 68.0 Training loss: 1.3557 Epsilon: 0.2344\n",
      "Episode: 455 Total reward: 94.0 Training loss: 61.6880 Epsilon: 0.2323\n",
      "Episode: 456 Total reward: 71.0 Training loss: 1.2777 Epsilon: 0.2307\n",
      "Episode: 457 Total reward: 90.0 Training loss: 1.3174 Epsilon: 0.2287\n",
      "Episode: 458 Total reward: 133.0 Training loss: 128.0802 Epsilon: 0.2259\n",
      "Episode: 459 Total reward: 31.0 Training loss: 62.0213 Epsilon: 0.2252\n",
      "Episode: 460 Total reward: 67.0 Training loss: 0.7015 Epsilon: 0.2237\n",
      "Episode: 461 Total reward: 287.0 Training loss: 0.4822 Epsilon: 0.2177\n",
      "Episode: 462 Total reward: 60.0 Training loss: 0.8647 Epsilon: 0.2165\n",
      "Episode: 463 Total reward: 177.0 Training loss: 0.8535 Epsilon: 0.2128\n",
      "Episode: 464 Total reward: 260.0 Training loss: 2.0103 Epsilon: 0.2076\n",
      "Episode: 465 Total reward: 134.0 Training loss: 0.8615 Epsilon: 0.2050\n",
      "Episode: 466 Total reward: 227.0 Training loss: 66.7643 Epsilon: 0.2006\n",
      "Episode: 467 Total reward: 115.0 Training loss: 1.1069 Epsilon: 0.1984\n",
      "Episode: 468 Total reward: 154.0 Training loss: 1.2529 Epsilon: 0.1956\n",
      "Episode: 469 Total reward: 130.0 Training loss: 0.4555 Epsilon: 0.1932\n",
      "Episode: 470 Total reward: 143.0 Training loss: 0.4778 Epsilon: 0.1906\n",
      "Episode: 471 Total reward: 196.0 Training loss: 0.9382 Epsilon: 0.1871\n",
      "Episode: 472 Total reward: 184.0 Training loss: 0.9764 Epsilon: 0.1838\n",
      "Episode: 473 Total reward: 180.0 Training loss: 1.4992 Epsilon: 0.1807\n",
      "Episode: 474 Total reward: 166.0 Training loss: 1.1854 Epsilon: 0.1779\n",
      "Episode: 475 Total reward: 312.0 Training loss: 52.7416 Epsilon: 0.1728\n",
      "Episode: 476 Total reward: 137.0 Training loss: 1.9075 Epsilon: 0.1705\n",
      "Episode: 477 Total reward: 132.0 Training loss: 0.8181 Epsilon: 0.1684\n",
      "Episode: 478 Total reward: 219.0 Training loss: 0.9498 Epsilon: 0.1650\n",
      "Episode: 479 Total reward: 235.0 Training loss: 1.6614 Epsilon: 0.1614\n",
      "Episode: 480 Total reward: 265.0 Training loss: 67.5574 Epsilon: 0.1575\n",
      "Episode: 481 Total reward: 246.0 Training loss: 66.7400 Epsilon: 0.1539\n",
      "Episode: 482 Total reward: 137.0 Training loss: 1.0656 Epsilon: 0.1519\n",
      "Episode: 483 Total reward: 241.0 Training loss: 1.7551 Epsilon: 0.1485\n",
      "Episode: 484 Total reward: 152.0 Training loss: 1.5551 Epsilon: 0.1464\n",
      "Episode: 485 Total reward: 41.0 Training loss: 1.1806 Epsilon: 0.1459\n",
      "Episode: 486 Total reward: 129.0 Training loss: 0.8006 Epsilon: 0.1441\n",
      "Episode: 487 Total reward: 104.0 Training loss: 1.1901 Epsilon: 0.1428\n",
      "Episode: 488 Total reward: 107.0 Training loss: 1.5358 Epsilon: 0.1413\n",
      "Episode: 489 Total reward: 161.0 Training loss: 0.5914 Epsilon: 0.1392\n",
      "Episode: 490 Total reward: 252.0 Training loss: 1.4716 Epsilon: 0.1360\n",
      "Episode: 491 Total reward: 104.0 Training loss: 1.1365 Epsilon: 0.1347\n",
      "Episode: 492 Total reward: 116.0 Training loss: 1.3221 Epsilon: 0.1333\n",
      "Episode: 493 Total reward: 100.0 Training loss: 1.6610 Epsilon: 0.1321\n",
      "Episode: 494 Total reward: 109.0 Training loss: 0.5728 Epsilon: 0.1307\n",
      "Episode: 495 Total reward: 50.0 Training loss: 1.3204 Epsilon: 0.1301\n",
      "Episode: 496 Total reward: 36.0 Training loss: 1.2837 Epsilon: 0.1297\n",
      "Episode: 497 Total reward: 40.0 Training loss: 118.2221 Epsilon: 0.1292\n",
      "Episode: 498 Total reward: 47.0 Training loss: 1.2472 Epsilon: 0.1287\n",
      "Episode: 499 Total reward: 96.0 Training loss: 1.4635 Epsilon: 0.1275\n",
      "Episode: 500 Total reward: 34.0 Training loss: 1.5876 Epsilon: 0.1271\n",
      "Episode: 501 Total reward: 31.0 Training loss: 0.7638 Epsilon: 0.1268\n",
      "Episode: 502 Total reward: 30.0 Training loss: 1.0511 Epsilon: 0.1264\n",
      "Episode: 503 Total reward: 27.0 Training loss: 2.1341 Epsilon: 0.1261\n",
      "Episode: 504 Total reward: 23.0 Training loss: 1.8260 Epsilon: 0.1258\n",
      "Episode: 505 Total reward: 24.0 Training loss: 1.0626 Epsilon: 0.1256\n",
      "Episode: 506 Total reward: 30.0 Training loss: 1.7368 Epsilon: 0.1252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 507 Total reward: 25.0 Training loss: 0.8357 Epsilon: 0.1249\n",
      "Episode: 508 Total reward: 18.0 Training loss: 302.3828 Epsilon: 0.1247\n",
      "Episode: 509 Total reward: 21.0 Training loss: 1.9696 Epsilon: 0.1245\n",
      "Episode: 510 Total reward: 23.0 Training loss: 2.7236 Epsilon: 0.1242\n",
      "Episode: 511 Total reward: 19.0 Training loss: 1.1180 Epsilon: 0.1240\n",
      "Episode: 512 Total reward: 22.0 Training loss: 554.8776 Epsilon: 0.1238\n",
      "Episode: 513 Total reward: 23.0 Training loss: 2.2141 Epsilon: 0.1235\n",
      "Episode: 514 Total reward: 22.0 Training loss: 0.9496 Epsilon: 0.1232\n",
      "Episode: 515 Total reward: 18.0 Training loss: 87.0895 Epsilon: 0.1230\n",
      "Episode: 516 Total reward: 16.0 Training loss: 1.7243 Epsilon: 0.1229\n",
      "Episode: 517 Total reward: 18.0 Training loss: 1.5886 Epsilon: 0.1227\n",
      "Episode: 518 Total reward: 22.0 Training loss: 1.8271 Epsilon: 0.1224\n",
      "Episode: 519 Total reward: 14.0 Training loss: 1.9353 Epsilon: 0.1222\n",
      "Episode: 520 Total reward: 16.0 Training loss: 1.7351 Epsilon: 0.1221\n",
      "Episode: 521 Total reward: 21.0 Training loss: 132.5024 Epsilon: 0.1218\n",
      "Episode: 522 Total reward: 24.0 Training loss: 0.7393 Epsilon: 0.1216\n",
      "Episode: 523 Total reward: 41.0 Training loss: 0.6265 Epsilon: 0.1211\n",
      "Episode: 524 Total reward: 56.0 Training loss: 2.0972 Epsilon: 0.1205\n",
      "Episode: 525 Total reward: 40.0 Training loss: 1.5995 Epsilon: 0.1200\n",
      "Episode: 526 Total reward: 38.0 Training loss: 1.9727 Epsilon: 0.1196\n",
      "Episode: 527 Total reward: 36.0 Training loss: 1.0606 Epsilon: 0.1192\n",
      "Episode: 528 Total reward: 182.0 Training loss: 1.9548 Epsilon: 0.1173\n",
      "Episode: 529 Total reward: 118.0 Training loss: 1.5517 Epsilon: 0.1160\n",
      "Episode: 530 Total reward: 216.0 Training loss: 105.6818 Epsilon: 0.1137\n",
      "Episode: 531 Total reward: 202.0 Training loss: 2.4091 Epsilon: 0.1117\n",
      "Episode: 532 Total reward: 164.0 Training loss: 1.0724 Epsilon: 0.1100\n",
      "Episode: 533 Total reward: 201.0 Training loss: 0.5133 Epsilon: 0.1080\n",
      "Episode: 534 Total reward: 188.0 Training loss: 0.5209 Epsilon: 0.1062\n",
      "Episode: 535 Total reward: 139.0 Training loss: 2.1215 Epsilon: 0.1049\n",
      "Episode: 536 Total reward: 174.0 Training loss: 1.2067 Epsilon: 0.1032\n",
      "Episode: 537 Total reward: 183.0 Training loss: 0.7577 Epsilon: 0.1015\n",
      "Episode: 538 Total reward: 184.0 Training loss: 0.7687 Epsilon: 0.0999\n",
      "Episode: 539 Total reward: 189.0 Training loss: 186.9604 Epsilon: 0.0982\n",
      "Episode: 540 Total reward: 301.0 Training loss: 0.4203 Epsilon: 0.0956\n",
      "Episode: 541 Total reward: 385.0 Training loss: 0.7077 Epsilon: 0.0923\n",
      "Episode: 542 Total reward: 457.0 Training loss: 0.5603 Epsilon: 0.0887\n",
      "Episode: 543 Total reward: 499.0 Training loss: 0.4661 Epsilon: 0.0848\n",
      "Episode: 544 Total reward: 499.0 Training loss: 0.3623 Epsilon: 0.0812\n",
      "Episode: 545 Total reward: 499.0 Training loss: 0.3931 Epsilon: 0.0777\n",
      "Episode: 546 Total reward: 499.0 Training loss: 0.3801 Epsilon: 0.0744\n",
      "Episode: 547 Total reward: 499.0 Training loss: 0.4714 Epsilon: 0.0713\n",
      "Episode: 548 Total reward: 424.0 Training loss: 0.3024 Epsilon: 0.0688\n",
      "Episode: 549 Total reward: 467.0 Training loss: 0.3867 Epsilon: 0.0661\n",
      "Episode: 550 Total reward: 123.0 Training loss: 0.1301 Epsilon: 0.0654\n",
      "Episode: 551 Total reward: 202.0 Training loss: 0.4340 Epsilon: 0.0643\n",
      "Episode: 552 Total reward: 159.0 Training loss: 0.7685 Epsilon: 0.0634\n",
      "Episode: 553 Total reward: 89.0 Training loss: 0.7096 Epsilon: 0.0629\n",
      "Episode: 554 Total reward: 63.0 Training loss: 1.2580 Epsilon: 0.0626\n",
      "Episode: 555 Total reward: 158.0 Training loss: 0.5263 Epsilon: 0.0618\n",
      "Episode: 556 Total reward: 214.0 Training loss: 0.8759 Epsilon: 0.0607\n",
      "Episode: 557 Total reward: 131.0 Training loss: 0.8450 Epsilon: 0.0600\n",
      "Episode: 558 Total reward: 130.0 Training loss: 0.8211 Epsilon: 0.0594\n",
      "Episode: 559 Total reward: 127.0 Training loss: 0.6767 Epsilon: 0.0588\n",
      "Episode: 560 Total reward: 161.0 Training loss: 0.7738 Epsilon: 0.0580\n",
      "Episode: 561 Total reward: 136.0 Training loss: 1.1610 Epsilon: 0.0573\n",
      "Episode: 562 Total reward: 126.0 Training loss: 1.4234 Epsilon: 0.0567\n",
      "Episode: 563 Total reward: 34.0 Training loss: 1.2621 Epsilon: 0.0566\n",
      "Episode: 564 Total reward: 29.0 Training loss: 276.8224 Epsilon: 0.0565\n",
      "Episode: 565 Total reward: 116.0 Training loss: 1.9785 Epsilon: 0.0559\n",
      "Episode: 566 Total reward: 31.0 Training loss: 1.1821 Epsilon: 0.0558\n",
      "Episode: 567 Total reward: 34.0 Training loss: 2.1357 Epsilon: 0.0556\n",
      "Episode: 568 Total reward: 21.0 Training loss: 1.1389 Epsilon: 0.0555\n",
      "Episode: 569 Total reward: 96.0 Training loss: 1.3294 Epsilon: 0.0551\n",
      "Episode: 570 Total reward: 106.0 Training loss: 0.9023 Epsilon: 0.0546\n",
      "Episode: 571 Total reward: 109.0 Training loss: 1.3945 Epsilon: 0.0541\n",
      "Episode: 572 Total reward: 98.0 Training loss: 1.8335 Epsilon: 0.0537\n",
      "Episode: 573 Total reward: 28.0 Training loss: 1.1325 Epsilon: 0.0536\n",
      "Episode: 574 Total reward: 17.0 Training loss: 1.5785 Epsilon: 0.0535\n",
      "Episode: 575 Total reward: 16.0 Training loss: 656.1351 Epsilon: 0.0534\n",
      "Episode: 576 Total reward: 21.0 Training loss: 1.2834 Epsilon: 0.0533\n",
      "Episode: 577 Total reward: 20.0 Training loss: 1.4718 Epsilon: 0.0533\n",
      "Episode: 578 Total reward: 23.0 Training loss: 1.2713 Epsilon: 0.0532\n",
      "Episode: 579 Total reward: 25.0 Training loss: 2.0958 Epsilon: 0.0530\n",
      "Episode: 580 Total reward: 16.0 Training loss: 461.0958 Epsilon: 0.0530\n",
      "Episode: 581 Total reward: 32.0 Training loss: 329.6935 Epsilon: 0.0528\n",
      "Episode: 582 Total reward: 20.0 Training loss: 1.4198 Epsilon: 0.0528\n",
      "Episode: 583 Total reward: 17.0 Training loss: 311.7184 Epsilon: 0.0527\n",
      "Episode: 584 Total reward: 29.0 Training loss: 1.0014 Epsilon: 0.0526\n",
      "Episode: 585 Total reward: 126.0 Training loss: 1.1091 Epsilon: 0.0520\n",
      "Episode: 586 Total reward: 28.0 Training loss: 1.7569 Epsilon: 0.0519\n",
      "Episode: 587 Total reward: 28.0 Training loss: 1.0765 Epsilon: 0.0518\n",
      "Episode: 588 Total reward: 120.0 Training loss: 401.3000 Epsilon: 0.0513\n",
      "Episode: 589 Total reward: 22.0 Training loss: 386.4724 Epsilon: 0.0512\n",
      "Episode: 590 Total reward: 113.0 Training loss: 1.4852 Epsilon: 0.0507\n",
      "Episode: 591 Total reward: 160.0 Training loss: 1.2491 Epsilon: 0.0501\n",
      "Episode: 592 Total reward: 261.0 Training loss: 0.8658 Epsilon: 0.0491\n",
      "Episode: 593 Total reward: 499.0 Training loss: 1.2755 Epsilon: 0.0472\n",
      "Episode: 594 Total reward: 454.0 Training loss: 287.4627 Epsilon: 0.0455\n",
      "Episode: 595 Total reward: 294.0 Training loss: 1.4960 Epsilon: 0.0445\n",
      "Episode: 596 Total reward: 229.0 Training loss: 1.4477 Epsilon: 0.0437\n",
      "Episode: 597 Total reward: 247.0 Training loss: 334.7219 Epsilon: 0.0429\n",
      "Episode: 598 Total reward: 303.0 Training loss: 316.6779 Epsilon: 0.0419\n",
      "Episode: 599 Total reward: 244.0 Training loss: 1.8720 Epsilon: 0.0411\n",
      "Episode: 600 Total reward: 231.0 Training loss: 1.4846 Epsilon: 0.0404\n",
      "Episode: 601 Total reward: 205.0 Training loss: 1.6846 Epsilon: 0.0398\n",
      "Episode: 602 Total reward: 215.0 Training loss: 1.6907 Epsilon: 0.0392\n",
      "Episode: 603 Total reward: 241.0 Training loss: 1.5563 Epsilon: 0.0385\n",
      "Episode: 604 Total reward: 176.0 Training loss: 2.8942 Epsilon: 0.0380\n",
      "Episode: 605 Total reward: 161.0 Training loss: 3.6218 Epsilon: 0.0375\n",
      "Episode: 606 Total reward: 96.0 Training loss: 1.8383 Epsilon: 0.0373\n",
      "Episode: 607 Total reward: 32.0 Training loss: 3.1169 Epsilon: 0.0372\n",
      "Episode: 608 Total reward: 129.0 Training loss: 3.6729 Epsilon: 0.0368\n",
      "Episode: 609 Total reward: 102.0 Training loss: 5.3861 Epsilon: 0.0366\n",
      "Episode: 610 Total reward: 16.0 Training loss: 975.4414 Epsilon: 0.0365\n",
      "Episode: 611 Total reward: 13.0 Training loss: 5.5422 Epsilon: 0.0365\n",
      "Episode: 612 Total reward: 13.0 Training loss: 4.9108 Epsilon: 0.0364\n",
      "Episode: 613 Total reward: 12.0 Training loss: 765.8409 Epsilon: 0.0364\n",
      "Episode: 614 Total reward: 17.0 Training loss: 5.8178 Epsilon: 0.0364\n",
      "Episode: 615 Total reward: 12.0 Training loss: 3.6782 Epsilon: 0.0363\n",
      "Episode: 616 Total reward: 13.0 Training loss: 4.9912 Epsilon: 0.0363\n",
      "Episode: 617 Total reward: 13.0 Training loss: 5.0528 Epsilon: 0.0363\n",
      "Episode: 618 Total reward: 14.0 Training loss: 4.7267 Epsilon: 0.0362\n",
      "Episode: 619 Total reward: 13.0 Training loss: 2.5733 Epsilon: 0.0362\n",
      "Episode: 620 Total reward: 17.0 Training loss: 5.0937 Epsilon: 0.0362\n",
      "Episode: 621 Total reward: 14.0 Training loss: 6.0618 Epsilon: 0.0361\n",
      "Episode: 622 Total reward: 16.0 Training loss: 3.7130 Epsilon: 0.0361\n",
      "Episode: 623 Total reward: 14.0 Training loss: 4.9048 Epsilon: 0.0360\n",
      "Episode: 624 Total reward: 11.0 Training loss: 6.7477 Epsilon: 0.0360\n",
      "Episode: 625 Total reward: 11.0 Training loss: 10.4151 Epsilon: 0.0360\n",
      "Episode: 626 Total reward: 10.0 Training loss: 5.1675 Epsilon: 0.0360\n",
      "Episode: 627 Total reward: 13.0 Training loss: 1354.6898 Epsilon: 0.0359\n",
      "Episode: 628 Total reward: 13.0 Training loss: 4.6243 Epsilon: 0.0359\n",
      "Episode: 629 Total reward: 16.0 Training loss: 3.6949 Epsilon: 0.0358\n",
      "Episode: 630 Total reward: 11.0 Training loss: 1194.5527 Epsilon: 0.0358\n",
      "Episode: 631 Total reward: 13.0 Training loss: 7.2428 Epsilon: 0.0358\n",
      "Episode: 632 Total reward: 11.0 Training loss: 4.9961 Epsilon: 0.0358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 633 Total reward: 12.0 Training loss: 5.3152 Epsilon: 0.0357\n",
      "Episode: 634 Total reward: 13.0 Training loss: 9.3164 Epsilon: 0.0357\n",
      "Episode: 635 Total reward: 10.0 Training loss: 7.7914 Epsilon: 0.0357\n",
      "Episode: 636 Total reward: 8.0 Training loss: 8.4832 Epsilon: 0.0356\n",
      "Episode: 637 Total reward: 10.0 Training loss: 8.2978 Epsilon: 0.0356\n",
      "Episode: 638 Total reward: 16.0 Training loss: 1434.7599 Epsilon: 0.0356\n",
      "Episode: 639 Total reward: 10.0 Training loss: 4.5956 Epsilon: 0.0356\n",
      "Episode: 640 Total reward: 14.0 Training loss: 932.8688 Epsilon: 0.0355\n",
      "Episode: 641 Total reward: 13.0 Training loss: 3.9004 Epsilon: 0.0355\n",
      "Episode: 642 Total reward: 12.0 Training loss: 6.4953 Epsilon: 0.0355\n",
      "Episode: 643 Total reward: 14.0 Training loss: 3.3754 Epsilon: 0.0354\n",
      "Episode: 644 Total reward: 14.0 Training loss: 3.2676 Epsilon: 0.0354\n",
      "Episode: 645 Total reward: 17.0 Training loss: 1288.5881 Epsilon: 0.0353\n",
      "Episode: 646 Total reward: 16.0 Training loss: 6.0662 Epsilon: 0.0353\n",
      "Episode: 647 Total reward: 14.0 Training loss: 4.8930 Epsilon: 0.0353\n",
      "Episode: 648 Total reward: 16.0 Training loss: 7.0974 Epsilon: 0.0352\n",
      "Episode: 649 Total reward: 14.0 Training loss: 5.1723 Epsilon: 0.0352\n",
      "Episode: 650 Total reward: 18.0 Training loss: 4.0247 Epsilon: 0.0351\n",
      "Episode: 651 Total reward: 12.0 Training loss: 4.0971 Epsilon: 0.0351\n",
      "Episode: 652 Total reward: 17.0 Training loss: 1408.3824 Epsilon: 0.0351\n",
      "Episode: 653 Total reward: 22.0 Training loss: 7.1864 Epsilon: 0.0350\n",
      "Episode: 654 Total reward: 15.0 Training loss: 514.1420 Epsilon: 0.0350\n",
      "Episode: 655 Total reward: 15.0 Training loss: 5.1798 Epsilon: 0.0349\n",
      "Episode: 656 Total reward: 14.0 Training loss: 229.3716 Epsilon: 0.0349\n",
      "Episode: 657 Total reward: 18.0 Training loss: 3.8881 Epsilon: 0.0349\n",
      "Episode: 658 Total reward: 309.0 Training loss: 4.0630 Epsilon: 0.0341\n",
      "Episode: 659 Total reward: 499.0 Training loss: 1.1331 Epsilon: 0.0329\n",
      "Episode: 660 Total reward: 281.0 Training loss: 2.0152 Epsilon: 0.0323\n",
      "Episode: 661 Total reward: 233.0 Training loss: 2.2441 Epsilon: 0.0318\n",
      "Episode: 662 Total reward: 239.0 Training loss: 293.4474 Epsilon: 0.0313\n",
      "Episode: 663 Total reward: 213.0 Training loss: 3.5179 Epsilon: 0.0308\n",
      "Episode: 664 Total reward: 230.0 Training loss: 376.7495 Epsilon: 0.0303\n",
      "Episode: 665 Total reward: 239.0 Training loss: 2.5219 Epsilon: 0.0299\n",
      "Episode: 666 Total reward: 187.0 Training loss: 6.5625 Epsilon: 0.0295\n",
      "Episode: 667 Total reward: 197.0 Training loss: 2.6939 Epsilon: 0.0291\n",
      "Episode: 668 Total reward: 203.0 Training loss: 4.4269 Epsilon: 0.0287\n",
      "Episode: 669 Total reward: 210.0 Training loss: 3.1900 Epsilon: 0.0283\n",
      "Episode: 670 Total reward: 173.0 Training loss: 3.5747 Epsilon: 0.0280\n",
      "Episode: 671 Total reward: 187.0 Training loss: 5.6667 Epsilon: 0.0277\n",
      "Episode: 672 Total reward: 156.0 Training loss: 3.1772 Epsilon: 0.0274\n",
      "Episode: 673 Total reward: 169.0 Training loss: 5.6464 Epsilon: 0.0271\n",
      "Episode: 674 Total reward: 24.0 Training loss: 7.1274 Epsilon: 0.0271\n",
      "Episode: 675 Total reward: 145.0 Training loss: 6.5217 Epsilon: 0.0268\n",
      "Episode: 676 Total reward: 143.0 Training loss: 448.7988 Epsilon: 0.0266\n",
      "Episode: 677 Total reward: 18.0 Training loss: 6.5085 Epsilon: 0.0266\n",
      "Episode: 678 Total reward: 17.0 Training loss: 8.4952 Epsilon: 0.0265\n",
      "Episode: 679 Total reward: 19.0 Training loss: 4.6851 Epsilon: 0.0265\n",
      "Episode: 680 Total reward: 19.0 Training loss: 2.7763 Epsilon: 0.0265\n",
      "Episode: 681 Total reward: 23.0 Training loss: 751.5670 Epsilon: 0.0264\n",
      "Episode: 682 Total reward: 17.0 Training loss: 4.9065 Epsilon: 0.0264\n",
      "Episode: 683 Total reward: 21.0 Training loss: 471.4341 Epsilon: 0.0264\n",
      "Episode: 684 Total reward: 166.0 Training loss: 540.1442 Epsilon: 0.0261\n",
      "Episode: 685 Total reward: 16.0 Training loss: 10.2169 Epsilon: 0.0261\n",
      "Episode: 686 Total reward: 16.0 Training loss: 6.1711 Epsilon: 0.0261\n",
      "Episode: 687 Total reward: 13.0 Training loss: 2.8611 Epsilon: 0.0260\n",
      "Episode: 688 Total reward: 19.0 Training loss: 11.1315 Epsilon: 0.0260\n",
      "Episode: 689 Total reward: 18.0 Training loss: 9.0468 Epsilon: 0.0260\n",
      "Episode: 690 Total reward: 18.0 Training loss: 8.5208 Epsilon: 0.0260\n",
      "Episode: 691 Total reward: 20.0 Training loss: 3.8865 Epsilon: 0.0259\n",
      "Episode: 692 Total reward: 22.0 Training loss: 6.3703 Epsilon: 0.0259\n",
      "Episode: 693 Total reward: 22.0 Training loss: 5.4069 Epsilon: 0.0259\n",
      "Episode: 694 Total reward: 14.0 Training loss: 6.8655 Epsilon: 0.0258\n",
      "Episode: 695 Total reward: 22.0 Training loss: 9.2175 Epsilon: 0.0258\n",
      "Episode: 696 Total reward: 24.0 Training loss: 7.4396 Epsilon: 0.0258\n",
      "Episode: 697 Total reward: 21.0 Training loss: 8.9690 Epsilon: 0.0257\n",
      "Episode: 698 Total reward: 19.0 Training loss: 4.7941 Epsilon: 0.0257\n",
      "Episode: 699 Total reward: 23.0 Training loss: 11.2382 Epsilon: 0.0257\n",
      "Episode: 700 Total reward: 20.0 Training loss: 4.7775 Epsilon: 0.0256\n",
      "Episode: 701 Total reward: 24.0 Training loss: 561.3009 Epsilon: 0.0256\n",
      "Episode: 702 Total reward: 23.0 Training loss: 3.3036 Epsilon: 0.0256\n",
      "Episode: 703 Total reward: 22.0 Training loss: 4.9180 Epsilon: 0.0255\n",
      "Episode: 704 Total reward: 18.0 Training loss: 3.4792 Epsilon: 0.0255\n",
      "Episode: 705 Total reward: 20.0 Training loss: 13.6994 Epsilon: 0.0255\n",
      "Episode: 706 Total reward: 19.0 Training loss: 7.8197 Epsilon: 0.0254\n",
      "Episode: 707 Total reward: 13.0 Training loss: 584.5856 Epsilon: 0.0254\n",
      "Episode: 708 Total reward: 15.0 Training loss: 449.5179 Epsilon: 0.0254\n",
      "Episode: 709 Total reward: 17.0 Training loss: 498.2338 Epsilon: 0.0254\n",
      "Episode: 710 Total reward: 16.0 Training loss: 11.3157 Epsilon: 0.0253\n",
      "Episode: 711 Total reward: 19.0 Training loss: 12.4918 Epsilon: 0.0253\n",
      "Episode: 712 Total reward: 20.0 Training loss: 6.0511 Epsilon: 0.0253\n",
      "Episode: 713 Total reward: 13.0 Training loss: 5.0120 Epsilon: 0.0253\n",
      "Episode: 714 Total reward: 18.0 Training loss: 10.5780 Epsilon: 0.0252\n",
      "Episode: 715 Total reward: 17.0 Training loss: 3.7864 Epsilon: 0.0252\n",
      "Episode: 716 Total reward: 20.0 Training loss: 4.7688 Epsilon: 0.0252\n",
      "Episode: 717 Total reward: 14.0 Training loss: 5.2924 Epsilon: 0.0252\n",
      "Episode: 718 Total reward: 21.0 Training loss: 7.2063 Epsilon: 0.0251\n",
      "Episode: 719 Total reward: 18.0 Training loss: 508.7316 Epsilon: 0.0251\n",
      "Episode: 720 Total reward: 14.0 Training loss: 5.0445 Epsilon: 0.0251\n",
      "Episode: 721 Total reward: 13.0 Training loss: 4.3381 Epsilon: 0.0251\n",
      "Episode: 722 Total reward: 14.0 Training loss: 252.4434 Epsilon: 0.0250\n",
      "Episode: 723 Total reward: 16.0 Training loss: 15.7828 Epsilon: 0.0250\n",
      "Episode: 724 Total reward: 19.0 Training loss: 6.7789 Epsilon: 0.0250\n",
      "Episode: 725 Total reward: 22.0 Training loss: 8.0052 Epsilon: 0.0249\n",
      "Episode: 726 Total reward: 24.0 Training loss: 5.3097 Epsilon: 0.0249\n",
      "Episode: 727 Total reward: 24.0 Training loss: 4.1724 Epsilon: 0.0249\n",
      "Episode: 728 Total reward: 17.0 Training loss: 466.9614 Epsilon: 0.0248\n",
      "Episode: 729 Total reward: 22.0 Training loss: 14.1940 Epsilon: 0.0248\n",
      "Episode: 730 Total reward: 18.0 Training loss: 4.1453 Epsilon: 0.0248\n",
      "Episode: 731 Total reward: 18.0 Training loss: 318.4201 Epsilon: 0.0248\n",
      "Episode: 732 Total reward: 22.0 Training loss: 6.5502 Epsilon: 0.0247\n",
      "Episode: 733 Total reward: 20.0 Training loss: 9.0995 Epsilon: 0.0247\n",
      "Episode: 734 Total reward: 16.0 Training loss: 6.4720 Epsilon: 0.0247\n",
      "Episode: 735 Total reward: 19.0 Training loss: 593.0773 Epsilon: 0.0246\n",
      "Episode: 736 Total reward: 19.0 Training loss: 5.4754 Epsilon: 0.0246\n",
      "Episode: 737 Total reward: 15.0 Training loss: 4.1321 Epsilon: 0.0246\n",
      "Episode: 738 Total reward: 15.0 Training loss: 4.1249 Epsilon: 0.0246\n",
      "Episode: 739 Total reward: 20.0 Training loss: 4.9282 Epsilon: 0.0245\n",
      "Episode: 740 Total reward: 17.0 Training loss: 594.3256 Epsilon: 0.0245\n",
      "Episode: 741 Total reward: 16.0 Training loss: 2.7340 Epsilon: 0.0245\n",
      "Episode: 742 Total reward: 17.0 Training loss: 5.2459 Epsilon: 0.0245\n",
      "Episode: 743 Total reward: 20.0 Training loss: 436.7543 Epsilon: 0.0244\n",
      "Episode: 744 Total reward: 14.0 Training loss: 8.1535 Epsilon: 0.0244\n",
      "Episode: 745 Total reward: 18.0 Training loss: 494.3694 Epsilon: 0.0244\n",
      "Episode: 746 Total reward: 19.0 Training loss: 6.9491 Epsilon: 0.0244\n",
      "Episode: 747 Total reward: 25.0 Training loss: 6.6460 Epsilon: 0.0243\n",
      "Episode: 748 Total reward: 137.0 Training loss: 7.6250 Epsilon: 0.0241\n",
      "Episode: 749 Total reward: 165.0 Training loss: 2.1034 Epsilon: 0.0239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 750 Total reward: 193.0 Training loss: 10.6497 Epsilon: 0.0236\n",
      "Episode: 751 Total reward: 245.0 Training loss: 4.4834 Epsilon: 0.0233\n",
      "Episode: 752 Total reward: 499.0 Training loss: 3.1278 Epsilon: 0.0227\n",
      "Episode: 753 Total reward: 430.0 Training loss: 6.7297 Epsilon: 0.0221\n",
      "Episode: 754 Total reward: 412.0 Training loss: 1.7403 Epsilon: 0.0216\n",
      "Episode: 755 Total reward: 499.0 Training loss: 4.3917 Epsilon: 0.0211\n",
      "Episode: 756 Total reward: 288.0 Training loss: 1.5160 Epsilon: 0.0208\n",
      "Episode: 757 Total reward: 323.0 Training loss: 3.2289 Epsilon: 0.0204\n",
      "Episode: 758 Total reward: 381.0 Training loss: 1.2445 Epsilon: 0.0200\n",
      "Episode: 759 Total reward: 468.0 Training loss: 0.8396 Epsilon: 0.0196\n",
      "Episode: 760 Total reward: 286.0 Training loss: 299.7230 Epsilon: 0.0193\n",
      "Episode: 761 Total reward: 230.0 Training loss: 204.0134 Epsilon: 0.0191\n",
      "Episode: 762 Total reward: 258.0 Training loss: 1.1457 Epsilon: 0.0189\n",
      "Episode: 763 Total reward: 361.0 Training loss: 0.7914 Epsilon: 0.0185\n",
      "Episode: 764 Total reward: 255.0 Training loss: 1.3725 Epsilon: 0.0183\n",
      "Episode: 765 Total reward: 234.0 Training loss: 0.9205 Epsilon: 0.0181\n",
      "Episode: 766 Total reward: 248.0 Training loss: 1.6500 Epsilon: 0.0179\n",
      "Episode: 767 Total reward: 280.0 Training loss: 1.4445 Epsilon: 0.0177\n",
      "Episode: 768 Total reward: 228.0 Training loss: 1.1712 Epsilon: 0.0175\n",
      "Episode: 769 Total reward: 288.0 Training loss: 0.3864 Epsilon: 0.0173\n",
      "Episode: 770 Total reward: 337.0 Training loss: 0.8282 Epsilon: 0.0171\n",
      "Episode: 771 Total reward: 251.0 Training loss: 0.4638 Epsilon: 0.0169\n",
      "Episode: 772 Total reward: 274.0 Training loss: 128.5858 Epsilon: 0.0167\n",
      "Episode: 773 Total reward: 272.0 Training loss: 0.9589 Epsilon: 0.0165\n",
      "Episode: 774 Total reward: 244.0 Training loss: 1.6740 Epsilon: 0.0164\n",
      "Episode: 775 Total reward: 255.0 Training loss: 2.1726 Epsilon: 0.0162\n",
      "Episode: 776 Total reward: 316.0 Training loss: 1.4788 Epsilon: 0.0160\n",
      "Episode: 777 Total reward: 256.0 Training loss: 2.0572 Epsilon: 0.0159\n",
      "Episode: 778 Total reward: 251.0 Training loss: 1.3129 Epsilon: 0.0157\n",
      "Episode: 779 Total reward: 256.0 Training loss: 0.5303 Epsilon: 0.0156\n",
      "Episode: 780 Total reward: 269.0 Training loss: 0.8791 Epsilon: 0.0154\n",
      "Episode: 781 Total reward: 221.0 Training loss: 1.0846 Epsilon: 0.0153\n",
      "Episode: 782 Total reward: 257.0 Training loss: 1.0133 Epsilon: 0.0152\n",
      "Episode: 783 Total reward: 241.0 Training loss: 0.3402 Epsilon: 0.0151\n",
      "Episode: 784 Total reward: 207.0 Training loss: 156.2756 Epsilon: 0.0150\n",
      "Episode: 785 Total reward: 253.0 Training loss: 0.3196 Epsilon: 0.0148\n",
      "Episode: 786 Total reward: 266.0 Training loss: 0.1384 Epsilon: 0.0147\n",
      "Episode: 787 Total reward: 277.0 Training loss: 0.5984 Epsilon: 0.0146\n",
      "Episode: 788 Total reward: 238.0 Training loss: 0.4959 Epsilon: 0.0145\n",
      "Episode: 789 Total reward: 269.0 Training loss: 90.2363 Epsilon: 0.0144\n",
      "Episode: 790 Total reward: 262.0 Training loss: 0.1792 Epsilon: 0.0142\n",
      "Episode: 791 Total reward: 218.0 Training loss: 0.4786 Epsilon: 0.0141\n",
      "Episode: 792 Total reward: 207.0 Training loss: 50.1073 Epsilon: 0.0141\n",
      "Episode: 793 Total reward: 237.0 Training loss: 0.8114 Epsilon: 0.0140\n",
      "Episode: 794 Total reward: 221.0 Training loss: 0.1298 Epsilon: 0.0139\n",
      "Episode: 795 Total reward: 199.0 Training loss: 41.6854 Epsilon: 0.0138\n",
      "Episode: 796 Total reward: 236.0 Training loss: 0.2030 Epsilon: 0.0137\n",
      "Episode: 797 Total reward: 205.0 Training loss: 0.2400 Epsilon: 0.0136\n",
      "Episode: 798 Total reward: 232.0 Training loss: 0.1662 Epsilon: 0.0136\n",
      "Episode: 799 Total reward: 239.0 Training loss: 0.3775 Epsilon: 0.0135\n",
      "Episode: 800 Total reward: 239.0 Training loss: 0.1981 Epsilon: 0.0134\n",
      "Episode: 801 Total reward: 212.0 Training loss: 0.8363 Epsilon: 0.0133\n",
      "Episode: 802 Total reward: 223.0 Training loss: 0.1122 Epsilon: 0.0132\n",
      "Episode: 803 Total reward: 210.0 Training loss: 0.1117 Epsilon: 0.0132\n",
      "Episode: 804 Total reward: 244.0 Training loss: 0.4277 Epsilon: 0.0131\n",
      "Episode: 805 Total reward: 214.0 Training loss: 0.1625 Epsilon: 0.0130\n",
      "Episode: 806 Total reward: 248.0 Training loss: 0.0963 Epsilon: 0.0130\n",
      "Episode: 807 Total reward: 225.0 Training loss: 0.2010 Epsilon: 0.0129\n",
      "Episode: 808 Total reward: 211.0 Training loss: 0.1320 Epsilon: 0.0128\n",
      "Episode: 809 Total reward: 246.0 Training loss: 0.0660 Epsilon: 0.0128\n",
      "Episode: 810 Total reward: 271.0 Training loss: 0.2108 Epsilon: 0.0127\n",
      "Episode: 811 Total reward: 216.0 Training loss: 0.1053 Epsilon: 0.0126\n",
      "Episode: 812 Total reward: 248.0 Training loss: 0.0733 Epsilon: 0.0126\n",
      "Episode: 813 Total reward: 274.0 Training loss: 0.0733 Epsilon: 0.0125\n",
      "Episode: 814 Total reward: 205.0 Training loss: 0.1930 Epsilon: 0.0125\n",
      "Episode: 815 Total reward: 250.0 Training loss: 0.0525 Epsilon: 0.0124\n",
      "Episode: 816 Total reward: 233.0 Training loss: 0.1978 Epsilon: 0.0123\n",
      "Episode: 817 Total reward: 225.0 Training loss: 0.1224 Epsilon: 0.0123\n",
      "Episode: 818 Total reward: 231.0 Training loss: 0.1059 Epsilon: 0.0122\n",
      "Episode: 819 Total reward: 227.0 Training loss: 0.0666 Epsilon: 0.0122\n",
      "Episode: 820 Total reward: 262.0 Training loss: 0.1196 Epsilon: 0.0121\n",
      "Episode: 821 Total reward: 257.0 Training loss: 0.0526 Epsilon: 0.0121\n",
      "Episode: 822 Total reward: 265.0 Training loss: 0.1333 Epsilon: 0.0120\n",
      "Episode: 823 Total reward: 266.0 Training loss: 0.1039 Epsilon: 0.0120\n",
      "Episode: 824 Total reward: 282.0 Training loss: 0.1276 Epsilon: 0.0119\n",
      "Episode: 825 Total reward: 245.0 Training loss: 0.0703 Epsilon: 0.0119\n",
      "Episode: 826 Total reward: 279.0 Training loss: 0.0513 Epsilon: 0.0118\n",
      "Episode: 827 Total reward: 238.0 Training loss: 0.0610 Epsilon: 0.0118\n",
      "Episode: 828 Total reward: 276.0 Training loss: 1.8591 Epsilon: 0.0117\n",
      "Episode: 829 Total reward: 280.0 Training loss: 0.1607 Epsilon: 0.0117\n",
      "Episode: 830 Total reward: 294.0 Training loss: 0.0584 Epsilon: 0.0116\n",
      "Episode: 831 Total reward: 322.0 Training loss: 0.0436 Epsilon: 0.0116\n",
      "Episode: 832 Total reward: 367.0 Training loss: 0.8486 Epsilon: 0.0115\n",
      "Episode: 833 Total reward: 344.0 Training loss: 0.0353 Epsilon: 0.0115\n",
      "Episode: 834 Total reward: 290.0 Training loss: 1.6060 Epsilon: 0.0114\n",
      "Episode: 835 Total reward: 330.0 Training loss: 0.0443 Epsilon: 0.0114\n",
      "Episode: 836 Total reward: 389.0 Training loss: 1.6490 Epsilon: 0.0113\n",
      "Episode: 837 Total reward: 421.0 Training loss: 0.1144 Epsilon: 0.0113\n",
      "Episode: 838 Total reward: 290.0 Training loss: 0.1939 Epsilon: 0.0112\n",
      "Episode: 839 Total reward: 320.0 Training loss: 0.0739 Epsilon: 0.0112\n",
      "Episode: 840 Total reward: 346.0 Training loss: 0.0311 Epsilon: 0.0112\n",
      "Episode: 841 Total reward: 363.0 Training loss: 0.0561 Epsilon: 0.0111\n",
      "Episode: 842 Total reward: 302.0 Training loss: 0.0780 Epsilon: 0.0111\n",
      "Episode: 843 Total reward: 496.0 Training loss: 0.0454 Epsilon: 0.0110\n",
      "Episode: 844 Total reward: 499.0 Training loss: 0.0950 Epsilon: 0.0110\n",
      "Episode: 845 Total reward: 315.0 Training loss: 0.0372 Epsilon: 0.0109\n",
      "Episode: 846 Total reward: 311.0 Training loss: 4.5699 Epsilon: 0.0109\n",
      "Episode: 847 Total reward: 478.0 Training loss: 0.1638 Epsilon: 0.0109\n",
      "Episode: 848 Total reward: 499.0 Training loss: 0.1221 Epsilon: 0.0108\n",
      "Episode: 849 Total reward: 457.0 Training loss: 0.1190 Epsilon: 0.0108\n",
      "Episode: 850 Total reward: 368.0 Training loss: 0.1141 Epsilon: 0.0108\n",
      "Episode: 851 Total reward: 499.0 Training loss: 0.2821 Epsilon: 0.0107\n",
      "Episode: 852 Total reward: 499.0 Training loss: 0.2136 Epsilon: 0.0107\n",
      "Episode: 853 Total reward: 496.0 Training loss: 0.0821 Epsilon: 0.0107\n",
      "Episode: 854 Total reward: 430.0 Training loss: 0.1881 Epsilon: 0.0106\n",
      "Episode: 855 Total reward: 499.0 Training loss: 0.1416 Epsilon: 0.0106\n",
      "Episode: 856 Total reward: 480.0 Training loss: 0.0822 Epsilon: 0.0106\n",
      "Episode: 857 Total reward: 499.0 Training loss: 0.2158 Epsilon: 0.0105\n",
      "Episode: 858 Total reward: 499.0 Training loss: 0.2479 Epsilon: 0.0105\n",
      "Episode: 859 Total reward: 499.0 Training loss: 0.1542 Epsilon: 0.0105\n",
      "Episode: 860 Total reward: 499.0 Training loss: 0.4644 Epsilon: 0.0105\n",
      "Episode: 861 Total reward: 480.0 Training loss: 0.3872 Epsilon: 0.0104\n",
      "Episode: 862 Total reward: 420.0 Training loss: 0.2436 Epsilon: 0.0104\n",
      "Episode: 863 Total reward: 499.0 Training loss: 0.1323 Epsilon: 0.0104\n",
      "Episode: 864 Total reward: 499.0 Training loss: 0.2026 Epsilon: 0.0104\n",
      "Episode: 865 Total reward: 499.0 Training loss: 0.2823 Epsilon: 0.0104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 866 Total reward: 499.0 Training loss: 0.2628 Epsilon: 0.0104\n",
      "Episode: 867 Total reward: 499.0 Training loss: 0.1465 Epsilon: 0.0103\n",
      "Episode: 868 Total reward: 499.0 Training loss: 0.2702 Epsilon: 0.0103\n",
      "Episode: 869 Total reward: 343.0 Training loss: 0.2242 Epsilon: 0.0103\n",
      "Episode: 870 Total reward: 499.0 Training loss: 0.1864 Epsilon: 0.0103\n",
      "Episode: 871 Total reward: 499.0 Training loss: 0.1409 Epsilon: 0.0103\n",
      "Episode: 872 Total reward: 499.0 Training loss: 0.1564 Epsilon: 0.0103\n",
      "Episode: 873 Total reward: 499.0 Training loss: 0.1657 Epsilon: 0.0103\n",
      "Episode: 874 Total reward: 499.0 Training loss: 0.1908 Epsilon: 0.0102\n",
      "Episode: 875 Total reward: 499.0 Training loss: 0.2210 Epsilon: 0.0102\n",
      "Episode: 876 Total reward: 499.0 Training loss: 0.1578 Epsilon: 0.0102\n",
      "Episode: 877 Total reward: 499.0 Training loss: 0.2042 Epsilon: 0.0102\n",
      "Episode: 878 Total reward: 499.0 Training loss: 0.1256 Epsilon: 0.0102\n",
      "Episode: 879 Total reward: 499.0 Training loss: 0.1145 Epsilon: 0.0102\n",
      "Episode: 880 Total reward: 499.0 Training loss: 0.1030 Epsilon: 0.0102\n",
      "Episode: 881 Total reward: 499.0 Training loss: 0.1656 Epsilon: 0.0102\n",
      "Episode: 882 Total reward: 499.0 Training loss: 0.1645 Epsilon: 0.0102\n",
      "Episode: 883 Total reward: 499.0 Training loss: 0.4588 Epsilon: 0.0102\n",
      "Episode: 884 Total reward: 499.0 Training loss: 0.1236 Epsilon: 0.0101\n",
      "Episode: 885 Total reward: 499.0 Training loss: 0.1437 Epsilon: 0.0101\n",
      "Episode: 886 Total reward: 499.0 Training loss: 0.1582 Epsilon: 0.0101\n",
      "Episode: 887 Total reward: 499.0 Training loss: 0.1738 Epsilon: 0.0101\n",
      "Episode: 888 Total reward: 499.0 Training loss: 0.3908 Epsilon: 0.0101\n",
      "Episode: 889 Total reward: 499.0 Training loss: 0.2209 Epsilon: 0.0101\n",
      "Episode: 890 Total reward: 499.0 Training loss: 158.3285 Epsilon: 0.0101\n",
      "Episode: 891 Total reward: 499.0 Training loss: 0.0949 Epsilon: 0.0101\n",
      "Episode: 892 Total reward: 499.0 Training loss: 0.1285 Epsilon: 0.0101\n",
      "Episode: 893 Total reward: 499.0 Training loss: 0.0998 Epsilon: 0.0101\n",
      "Episode: 894 Total reward: 499.0 Training loss: 0.1113 Epsilon: 0.0101\n",
      "Episode: 895 Total reward: 499.0 Training loss: 0.1479 Epsilon: 0.0101\n",
      "Episode: 896 Total reward: 499.0 Training loss: 0.0730 Epsilon: 0.0101\n",
      "Episode: 897 Total reward: 499.0 Training loss: 0.1064 Epsilon: 0.0101\n",
      "Episode: 898 Total reward: 499.0 Training loss: 0.3278 Epsilon: 0.0101\n",
      "Episode: 899 Total reward: 499.0 Training loss: 0.1642 Epsilon: 0.0101\n",
      "Episode: 900 Total reward: 499.0 Training loss: 0.1696 Epsilon: 0.0101\n",
      "Episode: 901 Total reward: 499.0 Training loss: 0.1465 Epsilon: 0.0101\n",
      "Episode: 902 Total reward: 499.0 Training loss: 0.1900 Epsilon: 0.0101\n",
      "Episode: 903 Total reward: 499.0 Training loss: 0.1558 Epsilon: 0.0101\n",
      "Episode: 904 Total reward: 499.0 Training loss: 0.2156 Epsilon: 0.0101\n",
      "Episode: 905 Total reward: 499.0 Training loss: 0.1144 Epsilon: 0.0101\n",
      "Episode: 906 Total reward: 499.0 Training loss: 0.1595 Epsilon: 0.0100\n",
      "Episode: 907 Total reward: 499.0 Training loss: 0.1164 Epsilon: 0.0100\n",
      "Episode: 908 Total reward: 499.0 Training loss: 0.1405 Epsilon: 0.0100\n",
      "Episode: 909 Total reward: 499.0 Training loss: 0.1577 Epsilon: 0.0100\n",
      "Episode: 910 Total reward: 499.0 Training loss: 0.1037 Epsilon: 0.0100\n",
      "Episode: 911 Total reward: 499.0 Training loss: 0.1900 Epsilon: 0.0100\n",
      "Episode: 912 Total reward: 499.0 Training loss: 0.1503 Epsilon: 0.0100\n",
      "Episode: 913 Total reward: 499.0 Training loss: 0.2980 Epsilon: 0.0100\n",
      "Episode: 914 Total reward: 499.0 Training loss: 0.1648 Epsilon: 0.0100\n",
      "Episode: 915 Total reward: 499.0 Training loss: 0.2258 Epsilon: 0.0100\n",
      "Episode: 916 Total reward: 499.0 Training loss: 0.1524 Epsilon: 0.0100\n",
      "Episode: 917 Total reward: 499.0 Training loss: 0.3470 Epsilon: 0.0100\n",
      "Episode: 918 Total reward: 499.0 Training loss: 0.0927 Epsilon: 0.0100\n",
      "Episode: 919 Total reward: 499.0 Training loss: 0.2279 Epsilon: 0.0100\n",
      "Episode: 920 Total reward: 499.0 Training loss: 0.0787 Epsilon: 0.0100\n",
      "Episode: 921 Total reward: 499.0 Training loss: 0.0651 Epsilon: 0.0100\n",
      "Episode: 922 Total reward: 499.0 Training loss: 0.0748 Epsilon: 0.0100\n",
      "Episode: 923 Total reward: 499.0 Training loss: 198.7849 Epsilon: 0.0100\n",
      "Episode: 924 Total reward: 499.0 Training loss: 0.0868 Epsilon: 0.0100\n",
      "Episode: 925 Total reward: 499.0 Training loss: 0.0910 Epsilon: 0.0100\n",
      "Episode: 926 Total reward: 499.0 Training loss: 0.1556 Epsilon: 0.0100\n",
      "Episode: 927 Total reward: 499.0 Training loss: 0.0863 Epsilon: 0.0100\n",
      "Episode: 928 Total reward: 499.0 Training loss: 0.0858 Epsilon: 0.0100\n",
      "Episode: 929 Total reward: 499.0 Training loss: 0.2104 Epsilon: 0.0100\n",
      "Episode: 930 Total reward: 499.0 Training loss: 0.1549 Epsilon: 0.0100\n",
      "Episode: 931 Total reward: 499.0 Training loss: 0.2855 Epsilon: 0.0100\n",
      "Episode: 932 Total reward: 499.0 Training loss: 419.3384 Epsilon: 0.0100\n",
      "Episode: 933 Total reward: 499.0 Training loss: 0.1419 Epsilon: 0.0100\n",
      "Episode: 934 Total reward: 499.0 Training loss: 0.0964 Epsilon: 0.0100\n",
      "Episode: 935 Total reward: 499.0 Training loss: 0.1307 Epsilon: 0.0100\n",
      "Episode: 936 Total reward: 499.0 Training loss: 229.1968 Epsilon: 0.0100\n",
      "Episode: 937 Total reward: 499.0 Training loss: 0.1299 Epsilon: 0.0100\n",
      "Episode: 938 Total reward: 499.0 Training loss: 0.1300 Epsilon: 0.0100\n",
      "Episode: 939 Total reward: 499.0 Training loss: 0.1507 Epsilon: 0.0100\n",
      "Episode: 940 Total reward: 499.0 Training loss: 0.1035 Epsilon: 0.0100\n",
      "Episode: 941 Total reward: 499.0 Training loss: 0.0628 Epsilon: 0.0100\n",
      "Episode: 942 Total reward: 499.0 Training loss: 0.1177 Epsilon: 0.0100\n",
      "Episode: 943 Total reward: 499.0 Training loss: 0.0731 Epsilon: 0.0100\n",
      "Episode: 944 Total reward: 499.0 Training loss: 0.1662 Epsilon: 0.0100\n",
      "Episode: 945 Total reward: 499.0 Training loss: 0.1901 Epsilon: 0.0100\n",
      "Episode: 946 Total reward: 499.0 Training loss: 0.1309 Epsilon: 0.0100\n",
      "Episode: 947 Total reward: 499.0 Training loss: 0.1272 Epsilon: 0.0100\n",
      "Episode: 948 Total reward: 483.0 Training loss: 0.1309 Epsilon: 0.0100\n",
      "Episode: 949 Total reward: 426.0 Training loss: 0.0979 Epsilon: 0.0100\n",
      "Episode: 950 Total reward: 384.0 Training loss: 319.6430 Epsilon: 0.0100\n",
      "Episode: 951 Total reward: 303.0 Training loss: 0.1945 Epsilon: 0.0100\n",
      "Episode: 952 Total reward: 354.0 Training loss: 0.1029 Epsilon: 0.0100\n",
      "Episode: 953 Total reward: 383.0 Training loss: 0.1205 Epsilon: 0.0100\n",
      "Episode: 954 Total reward: 328.0 Training loss: 0.2486 Epsilon: 0.0100\n",
      "Episode: 955 Total reward: 309.0 Training loss: 0.1954 Epsilon: 0.0100\n",
      "Episode: 956 Total reward: 301.0 Training loss: 0.3016 Epsilon: 0.0100\n",
      "Episode: 957 Total reward: 353.0 Training loss: 0.1525 Epsilon: 0.0100\n",
      "Episode: 958 Total reward: 370.0 Training loss: 0.2556 Epsilon: 0.0100\n",
      "Episode: 959 Total reward: 368.0 Training loss: 0.1847 Epsilon: 0.0100\n",
      "Episode: 960 Total reward: 440.0 Training loss: 0.2035 Epsilon: 0.0100\n",
      "Episode: 961 Total reward: 371.0 Training loss: 0.3837 Epsilon: 0.0100\n",
      "Episode: 962 Total reward: 418.0 Training loss: 0.2301 Epsilon: 0.0100\n",
      "Episode: 963 Total reward: 370.0 Training loss: 0.4307 Epsilon: 0.0100\n",
      "Episode: 964 Total reward: 357.0 Training loss: 0.2110 Epsilon: 0.0100\n",
      "Episode: 965 Total reward: 351.0 Training loss: 0.1243 Epsilon: 0.0100\n",
      "Episode: 966 Total reward: 312.0 Training loss: 0.2059 Epsilon: 0.0100\n",
      "Episode: 967 Total reward: 374.0 Training loss: 0.1077 Epsilon: 0.0100\n",
      "Episode: 968 Total reward: 402.0 Training loss: 0.1876 Epsilon: 0.0100\n",
      "Episode: 969 Total reward: 376.0 Training loss: 0.3113 Epsilon: 0.0100\n",
      "Episode: 970 Total reward: 440.0 Training loss: 0.1453 Epsilon: 0.0100\n",
      "Episode: 971 Total reward: 499.0 Training loss: 0.1201 Epsilon: 0.0100\n",
      "Episode: 972 Total reward: 499.0 Training loss: 0.1719 Epsilon: 0.0100\n",
      "Episode: 973 Total reward: 499.0 Training loss: 0.1103 Epsilon: 0.0100\n",
      "Episode: 974 Total reward: 499.0 Training loss: 0.2341 Epsilon: 0.0100\n",
      "Episode: 975 Total reward: 499.0 Training loss: 0.1181 Epsilon: 0.0100\n",
      "Episode: 976 Total reward: 438.0 Training loss: 0.1733 Epsilon: 0.0100\n",
      "Episode: 977 Total reward: 480.0 Training loss: 0.1165 Epsilon: 0.0100\n",
      "Episode: 978 Total reward: 499.0 Training loss: 0.2725 Epsilon: 0.0100\n",
      "Episode: 979 Total reward: 499.0 Training loss: 0.1206 Epsilon: 0.0100\n",
      "Episode: 980 Total reward: 499.0 Training loss: 0.2373 Epsilon: 0.0100\n",
      "Episode: 981 Total reward: 499.0 Training loss: 0.1343 Epsilon: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 982 Total reward: 499.0 Training loss: 0.1828 Epsilon: 0.0100\n",
      "Episode: 983 Total reward: 499.0 Training loss: 0.1225 Epsilon: 0.0100\n",
      "Episode: 984 Total reward: 499.0 Training loss: 0.2002 Epsilon: 0.0100\n",
      "Episode: 985 Total reward: 499.0 Training loss: 0.1672 Epsilon: 0.0100\n",
      "Episode: 986 Total reward: 499.0 Training loss: 0.0355 Epsilon: 0.0100\n",
      "Episode: 987 Total reward: 499.0 Training loss: 0.0566 Epsilon: 0.0100\n",
      "Episode: 988 Total reward: 499.0 Training loss: 0.1001 Epsilon: 0.0100\n",
      "Episode: 989 Total reward: 499.0 Training loss: 0.0906 Epsilon: 0.0100\n",
      "Episode: 990 Total reward: 499.0 Training loss: 0.0309 Epsilon: 0.0100\n",
      "Episode: 991 Total reward: 499.0 Training loss: 0.1462 Epsilon: 0.0100\n",
      "Episode: 992 Total reward: 499.0 Training loss: 0.1986 Epsilon: 0.0100\n",
      "Episode: 993 Total reward: 499.0 Training loss: 0.1252 Epsilon: 0.0100\n",
      "Episode: 994 Total reward: 499.0 Training loss: 0.0722 Epsilon: 0.0100\n",
      "Episode: 995 Total reward: 499.0 Training loss: 0.0994 Epsilon: 0.0100\n",
      "Episode: 996 Total reward: 499.0 Training loss: 0.0787 Epsilon: 0.0100\n",
      "Episode: 997 Total reward: 499.0 Training loss: 0.0685 Epsilon: 0.0100\n",
      "Episode: 998 Total reward: 499.0 Training loss: 0.0829 Epsilon: 0.0100\n",
      "Episode: 999 Total reward: 499.0 Training loss: 0.1028 Epsilon: 0.0100\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "agent = DeepQNet(name='agent', hidden=hidden_size, learning_rate=learning_rate)\n",
    "memory = Memory(max_size=memory_size)\n",
    "\n",
    "# seed memory\n",
    "print(\"Seeding memory...\")\n",
    "# get it moving\n",
    "env.reset()\n",
    "state, reward, done, _ = env.step(env.action_space.sample())\n",
    "for i in range(pretrain_length):\n",
    "    # Make a random action\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "    if done:\n",
    "        # The simulation fails so no next state\n",
    "        next_state = np.zeros(state.shape)\n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        \n",
    "        # Start new episode\n",
    "        env.reset()\n",
    "        # Take one random step to get the pole and cart moving\n",
    "        state, reward, done, _ = env.step(env.action_space.sample())\n",
    "    else:\n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        state = next_state\n",
    "\n",
    "print(\"Running training...\")\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    epsilon_counter = 0\n",
    "    for episode in range(train_episodes):\n",
    "        total_reward = 0\n",
    "        while not done:\n",
    "            # Explore/exploit trade-off\n",
    "            epsilon_counter += 1\n",
    "            epsilon = explore_stop + (explore_start - explore_stop) * np.exp(-decay_rate * epsilon_counter)\n",
    "            if epsilon > np.random.rand():\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                value = sess.run(agent.value, feed_dict={\n",
    "#                     agent.state: [state],\n",
    "                    agent.state: state.reshape((1, *state.shape))\n",
    "                })\n",
    "                action = np.argmax(value)\n",
    "            \n",
    "            # Take an action\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            \n",
    "            if done:\n",
    "                next_state = np.zeros(state.shape)\n",
    "                t = max_steps\n",
    "                memory.add((state, action, reward, next_state))\n",
    "                \n",
    "                print('Episode: {}'.format(episode),\n",
    "                      'Total reward: {}'.format(total_reward),\n",
    "                      'Training loss: {:.4f}'.format(loss),\n",
    "                      'Epsilon: {:.4f}'.format(epsilon))\n",
    "                \n",
    "                env.reset()\n",
    "                state, reward, done, _ = env.step(env.action_space.sample())\n",
    "                break\n",
    "            else:\n",
    "                memory.add((state, action, reward, next_state))\n",
    "                state = next_state\n",
    "            \n",
    "            # train\n",
    "            states, actions, rewards, next_states = zip(*memory.sample(batch_size))\n",
    "            # print(\"States\", states)\n",
    "            # print(\"Actions\", actions)\n",
    "            # print(\"Rewards\", rewards)\n",
    "            # print(\"Next states\", next_states)\n",
    "            \n",
    "            next_values = sess.run(agent.value, feed_dict={\n",
    "#                 agent.state: states,\n",
    "                agent.state: next_states,\n",
    "            })\n",
    "            episode_ends = (next_states == np.zeros(states[0].shape)).all(axis=1)\n",
    "            # next_values[episode_ends] = [0, 0]\n",
    "            next_values[episode_ends] = (0,0)\n",
    "            \n",
    "            targets = rewards + gamma * np.max(next_values, axis=1)\n",
    "            # print(\"Targets\", targets)\n",
    "            loss, _ = sess.run([agent.loss, agent.opt], feed_dict={\n",
    "                agent.state: states,\n",
    "                agent.target: targets,\n",
    "                agent.action: actions,\n",
    "            })\n",
    "            # print(\"Loss\", loss)\n",
    "        # break\n",
    "    saver.save(sess, \"checkpoints/cartpole.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/cartpole.ckpt\n",
      "[ 0.02398992  0.02048327 -0.00087136  0.00638182] 0 1.0\n",
      "[ 0.02439959 -0.17462617 -0.00074373  0.29878969] 0 1.0\n",
      "[ 0.02090706 -0.36973751  0.00523207  0.59123797] 0 1.0\n",
      "[ 0.01351231 -0.1746892   0.01705683  0.30020773] 1 1.0\n",
      "[0.01001853 0.02018553 0.02306098 0.01295262] 1 1.0\n",
      "[ 0.01042224 -0.17525943  0.02332003  0.31282142] 0 1.0\n",
      "[0.00691705 0.01952268 0.02957646 0.02758317] 1 1.0\n",
      "[ 0.0073075  -0.17601066  0.03012813  0.32944912] 0 1.0\n",
      "[0.00378729 0.01866973 0.03671711 0.04641738] 1 1.0\n",
      "[ 0.00416069  0.21324647  0.03764546 -0.23445861] 1 1.0\n",
      "[0.00842562 0.01760744 0.03295628 0.06985718] 0 1.0\n",
      "[ 0.00877776  0.21224178  0.03435343 -0.21224841] 1 1.0\n",
      "[0.0130226  0.01664593 0.03010846 0.09107017] 0 1.0\n",
      "[ 0.01335552  0.21132368  0.03192986 -0.19196355] 1 1.0\n",
      "[0.01758199 0.01575985 0.02809059 0.11061846] 0 1.0\n",
      "[ 0.01789719  0.21046825  0.03030296 -0.17307137] 1 1.0\n",
      "[0.02210655 0.014926   0.02684153 0.12901506] 0 1.0\n",
      "[ 0.02240507  0.20965336  0.02942183 -0.15508031] 1 1.0\n",
      "[0.02659814 0.01412277 0.02632023 0.14673741] 0 1.0\n",
      "[ 0.0268806   0.20885811  0.02925498 -0.13752717] 1 1.0\n",
      "[0.03105776 0.01332962 0.02650443 0.1642398 ] 0 1.0\n",
      "[ 0.03132435  0.20806233  0.02978923 -0.11996528] 1 1.0\n",
      "[ 0.0354856   0.40274509  0.02738992 -0.40310312] 1 1.0\n",
      "[ 0.0435405   0.20724559  0.01932786 -0.10191224] 0 1.0\n",
      "[0.04768541 0.01185206 0.01728962 0.19680536] 0 1.0\n",
      "[ 0.04792245  0.20672249  0.02122572 -0.09037371] 1 1.0\n",
      "[ 0.0520569   0.40153388  0.01941825 -0.37628507] 1 1.0\n",
      "[ 0.06008758  0.20614158  0.01189255 -0.07754327] 0 1.0\n",
      "[0.06421041 0.01085118 0.01034168 0.21886794] 0 1.0\n",
      "[ 0.06442744  0.20582378  0.01471904 -0.07053493] 1 1.0\n",
      "[0.06854391 0.01049394 0.01330834 0.22675534] 0 1.0\n",
      "[ 0.06875379  0.20542319  0.01784345 -0.06170011] 1 1.0\n",
      "[ 0.07286225  0.40028482  0.01660945 -0.34870033] 1 1.0\n",
      "[ 0.08086795  0.20493063  0.00963544 -0.0508265 ] 0 1.0\n",
      "[0.08496656 0.00967185 0.00861891 0.24488085] 0 1.0\n",
      "[ 0.08516     0.20466964  0.01351653 -0.04507105] 1 1.0\n",
      "[ 0.08925339  0.39959519  0.01261511 -0.33345893] 1 1.0\n",
      "[ 0.0972453   0.20429598  0.00594593 -0.03682468] 0 1.0\n",
      "[ 0.10133122  0.39933217  0.00520943 -0.32762569] 1 1.0\n",
      "[ 0.10931786  0.20413644 -0.00134308 -0.03330451] 0 1.0\n",
      "[ 0.11340059  0.00903377 -0.00200917  0.25895436] 0 1.0\n",
      "[ 0.11358126  0.20418435  0.00316992 -0.03436161] 1 1.0\n",
      "[0.11766495 0.00901708 0.00248268 0.25931977] 0 1.0\n",
      "[ 0.11784529  0.20410351  0.00766908 -0.03257905] 1 1.0\n",
      "[ 0.12192736  0.39911464  0.0070175  -0.32283247] 1 1.0\n",
      "[ 0.12990966  0.20389347  0.00056085 -0.02794479] 0 1.0\n",
      "[1.33987525e-01 8.76348170e-03 1.95398215e-06 2.64915036e-01] 0 1.0\n",
      "[ 0.13416279  0.20388541  0.00530025 -0.02776727] 1 1.0\n",
      "[ 0.1382405   0.39893095  0.00474491 -0.31877321] 1 1.0\n",
      "[ 0.14621912  0.20374174 -0.00163055 -0.0245977 ] 0 1.0\n",
      "[ 0.15029396  0.00864321 -0.00212251  0.26757033] 0 1.0\n",
      "[ 0.15046682  0.20379539  0.0032289  -0.0257813 ] 1 1.0\n",
      "[ 0.15454273  0.39887089  0.00271327 -0.31744373] 1 1.0\n",
      "[ 0.16252015  0.2037104  -0.0036356  -0.02390637] 0 1.0\n",
      "[ 0.16659435  0.00864077 -0.00411373  0.26762727] 0 1.0\n",
      "[ 0.16676717  0.20382119  0.00123882 -0.02635031] 1 1.0\n",
      "[0.17084359 0.00868149 0.00071181 0.26672322] 0 1.0\n",
      "[ 0.17101722  0.20379328  0.00604627 -0.02573511] 1 1.0\n",
      "[ 0.17509309  0.398828    0.00553157 -0.31650426] 1 1.0\n",
      "[ 0.18306965  0.2036277  -0.00079851 -0.02208201] 0 1.0\n",
      "[ 0.1871422   0.00851721 -0.00124015  0.27034887] 0 1.0\n",
      "[ 0.18731255  0.20365683  0.00416682 -0.02272495] 1 1.0\n",
      "[ 0.19138568  0.39871878  0.00371232 -0.31409029] 1 1.0\n",
      "[ 0.19936006  0.20354415 -0.00256948 -0.02023893] 0 1.0\n",
      "[ 0.20343094  0.00845914 -0.00297426  0.27163219] 0 1.0\n",
      "[ 0.20360012  0.2036234   0.00245838 -0.02198735] 1 1.0\n",
      "[ 0.20767259  0.39871001  0.00201864 -0.31389361] 1 1.0\n",
      "[ 0.21564679  0.20355936 -0.00425924 -0.02057476] 0 1.0\n",
      "[ 0.21971798  0.00849875 -0.00467073  0.2707613 ] 0 1.0\n",
      "[ 0.21988796  0.20368704  0.0007445  -0.02339114] 1 1.0\n",
      "[ 2.23961696e-01  3.98798309e-01  2.76672401e-04 -3.15839073e-01] 1 1.0\n",
      "[ 0.23193766  0.20367242 -0.00604011 -0.02306891] 0 1.0\n",
      "[ 0.23601111  0.00863761 -0.00650149  0.26770219] 0 1.0\n",
      "[ 0.23618386  0.20385174 -0.00114744 -0.02702424] 1 1.0\n",
      "[ 0.2402609   0.00874626 -0.00168793  0.26529644] 0 1.0\n",
      "[ 0.24043582  0.20389226  0.003618   -0.0279184 ] 1 1.0\n",
      "[ 0.24451367  0.39896214  0.00305963 -0.31945761] 1 1.0\n",
      "[ 0.25249291  0.20379675 -0.00332952 -0.02581137] 0 1.0\n",
      "[ 0.25656885  0.0087227  -0.00384575  0.2658192 ] 0 1.0\n",
      "[ 0.2567433   0.20389933  0.00147064 -0.02807422] 1 1.0\n",
      "[ 0.26082129  0.39900016  0.00090915 -0.32029278] 1 1.0\n",
      "[ 0.26880129  0.20386528 -0.0054967  -0.02732328] 0 1.0\n",
      "[ 0.2728786   0.00882258 -0.00604317  0.26362032] 0 1.0\n",
      "[ 0.27305505  0.20403027 -0.00077076 -0.03096254] 1 1.0\n",
      "[ 0.27713565  0.00891938 -0.00139001  0.2614771 ] 0 1.0\n",
      "[ 0.27731404  0.20406114  0.00383953 -0.03164393] 1 1.0\n",
      "[ 0.28139526  0.39912782  0.00320665 -0.32311298] 1 1.0\n",
      "[ 0.28937782  0.20396036 -0.00325561 -0.02942053] 0 1.0\n",
      "[ 0.29345703  0.00888524 -0.00384402  0.26223344] 0 1.0\n",
      "[ 0.29363473  0.20406186  0.00140065 -0.03165945] 1 1.0\n",
      "[ 0.29771597  0.39916369  0.00076746 -0.32390013] 1 1.0\n",
      "[ 0.30569924  0.20403082 -0.00571054 -0.03097527] 0 1.0\n",
      "[ 0.30977986  0.00899123 -0.00633005  0.25990046] 0 1.0\n",
      "[ 0.30995968  0.20420297 -0.00113204 -0.03477231] 1 1.0\n",
      "[ 0.31404374  0.00909727 -0.00182748  0.25755323] 0 1.0\n",
      "[ 0.31422569  0.20424526  0.00332358 -0.03570555] 1 1.0\n",
      "[ 0.31831059  0.3993194   0.00260947 -0.327338  ] 1 1.0\n",
      "[ 0.32629698  0.20416039 -0.00393729 -0.03383331] 0 1.0\n",
      "[ 0.33038019  0.00909512 -0.00461396  0.25760476] 0 1.0\n",
      "[ 0.33056209  0.20428264  0.00053814 -0.0365299 ] 1 1.0\n",
      "[ 3.34647744e-01  9.15297727e-03 -1.92460035e-04  2.56322771e-01] 0 1.0\n",
      "[ 0.3348308   0.20427768  0.004934   -0.03642085] 1 1.0\n",
      "[ 0.33891636  0.39932853  0.00420558 -0.32754298] 1 1.0\n",
      "[ 0.34690293  0.20414695 -0.00234528 -0.03353678] 0 1.0\n",
      "[ 0.35098587  0.00905871 -0.00301602  0.25840527] 0 1.0\n",
      "[ 0.35116704  0.20422359  0.00215209 -0.03522743] 1 1.0\n",
      "[ 0.35525151  0.39931462  0.00144754 -0.32723057] 1 1.0\n",
      "[ 0.36323781  0.20417209 -0.00509707 -0.0340915 ] 0 1.0\n",
      "[ 0.36732125  0.0091236  -0.0057789   0.25697889] 0 1.0\n",
      "[ 0.36750372  0.20432758 -0.00063932 -0.03752117] 1 1.0\n",
      "[ 0.37159027  0.0092148  -0.00138975  0.25495997] 0 1.0\n",
      "[ 0.37177457  0.20435657  0.00370945 -0.03816098] 1 1.0\n",
      "[ 0.3758617   0.39942513  0.00294623 -0.32967123] 1 1.0\n",
      "[ 0.3838502   0.20426136 -0.00364719 -0.03606066] 0 1.0\n",
      "[ 0.38793543  0.0091919  -0.0043684   0.25546931] 0 1.0\n",
      "[ 0.38811927  0.20437595  0.00074098 -0.03858827] 1 1.0\n",
      "[ 3.92206784e-01  9.24337866e-03 -3.07840089e-05  2.54328349e-01] 0 1.0\n",
      "[ 0.39239165  0.20436577  0.00505578 -0.03836429] 1 1.0\n",
      "[ 0.39647897  0.39941486  0.0042885  -0.32944779] 1 1.0\n",
      "[ 0.40446726  0.20423212 -0.00230046 -0.03541556] 0 1.0\n",
      "[ 0.40855191  0.00914323 -0.00300877  0.25654066] 0 1.0\n",
      "[ 0.40873477  0.20430801  0.00212204 -0.03708976] 1 1.0\n",
      "[ 0.41282093  0.39939947  0.00138025 -0.3291024 ] 1 1.0\n",
      "[ 0.42080892  0.2042579  -0.0052018  -0.03598453] 0 1.0\n",
      "[ 0.42489408  0.00921092 -0.00592149  0.25505265] 0 1.0\n",
      "[ 0.4250783   0.20441692 -0.00082044 -0.03949212] 1 1.0\n",
      "[ 0.42916664  0.00930674 -0.00161028  0.25293184] 0 1.0\n",
      "[ 0.42935277  0.20445165  0.00344836 -0.04025857] 1 1.0\n",
      "[ 0.4334418   0.39952398  0.00264319 -0.33185151] 1 1.0\n",
      "[ 0.44143228  0.20436451 -0.00399384 -0.03833623] 0 1.0\n",
      "[ 0.44551957  0.00930006 -0.00476057  0.25308393] 0 1.0\n",
      "[ 4.45705575e-01  2.04489659e-01  3.01109756e-04 -4.10967557e-02] 1 1.0\n",
      "[ 0.44979537  0.00936339 -0.00052083  0.25168116] 0 1.0\n",
      "[ 0.44998264  0.20449278  0.0045128  -0.041166  ] 1 1.0\n",
      "[ 0.45407249  0.39954972  0.00368948 -0.33242169] 1 1.0\n",
      "[ 0.46206349  0.20437545 -0.00295896 -0.03857757] 0 1.0\n",
      "[ 0.46615099  0.00929606 -0.00373051  0.25317031] 0 1.0\n",
      "[ 0.46633692  0.20447108  0.0013329  -0.04068695] 1 1.0\n",
      "[0.47042634 0.00933004 0.00051916 0.25241622] 0 1.0\n",
      "[ 0.47061294  0.20444457  0.00556748 -0.04010291] 1 1.0\n",
      "[ 0.47470183  0.39948625  0.00476543 -0.33102405] 1 1.0\n",
      "[ 0.48269155  0.20429679 -0.00185505 -0.03684215] 0 1.0\n",
      "[ 0.48677749  0.00920149 -0.0025919   0.25525491] 0 1.0\n",
      "[ 0.48696152  0.20436035  0.0025132  -0.03824442] 1 1.0\n",
      "[ 0.49104873  0.39944617  0.00174831 -0.33013335] 1 1.0\n",
      "[ 0.49903765  0.20429938 -0.00485435 -0.0368996 ] 0 1.0\n",
      "[ 0.50312364  0.00924737 -0.00559235  0.25424778] 0 1.0\n",
      "[ 0.50330859  0.20444872 -0.00050739 -0.04019381] 1 1.0\n",
      "[ 0.50739756  0.00933405 -0.00131127  0.25232899] 0 1.0\n",
      "[ 0.50758424  0.2044747   0.00373531 -0.04076725] 1 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.51167374  0.39954289  0.00291997 -0.33226931] 1 1.0\n",
      "[ 0.51966459  0.2043795  -0.00372542 -0.038667  ] 0 1.0\n",
      "[ 0.52375218  0.00931117 -0.00449876  0.25283819] 0 1.0\n",
      "[ 0.52393841  0.20449707  0.00055801 -0.04126032] 1 1.0\n",
      "[ 5.28028348e-01  9.36712023e-03 -2.67201322e-04  2.51598607e-01] 0 1.0\n",
      "[ 0.52821569  0.20449289  0.00476477 -0.04116859] 1 1.0\n",
      "[ 0.53230555  0.39954619  0.0039414  -0.33234438] 1 1.0\n",
      "[ 0.54029647  0.20436836 -0.00270549 -0.03842114] 0 1.0\n",
      "[ 0.54438384  0.00928531 -0.00347391  0.25340695] 0 1.0\n",
      "[ 0.54456954  0.20445669  0.00159423 -0.04036969] 1 1.0\n",
      "[ 0.54865868  0.39955574  0.00078683 -0.33254919] 1 1.0\n",
      "[ 0.55664979  0.2044226  -0.00586415 -0.03961824] 0 1.0\n",
      "[ 0.56073825  0.00938523 -0.00665651  0.25120873] 0 1.0\n",
      "[ 0.56092595  0.2046016  -0.00163234 -0.04356633] 1 1.0\n",
      "[ 0.56501798  0.0095031  -0.00250367  0.24860113] 0 1.0\n",
      "[ 0.56520804  0.20466071  0.00246836 -0.04487046] 1 1.0\n",
      "[ 0.56930126  0.39974718  0.00157095 -0.33677358] 1 1.0\n",
      "[ 0.5772962   0.20460291 -0.00516453 -0.04359567] 0 1.0\n",
      "[ 0.58138826  0.0095554  -0.00603644  0.24745334] 0 1.0\n",
      "[ 0.58157937  0.20476303 -0.00108737 -0.04712749] 1 1.0\n",
      "[ 0.58567463  0.00965669 -0.00202992  0.24521216] 0 1.0\n",
      "[ 0.58586776  0.20480758  0.00287432 -0.04811036] 1 1.0\n",
      "[ 0.58996391  0.3998882   0.00191211 -0.33988503] 1 1.0\n",
      "[ 0.59796168  0.20473909 -0.00488559 -0.04659974] 0 1.0\n",
      "[ 0.60205646  0.00968753 -0.00581758  0.24453774] 0 1.0\n",
      "[ 0.60225021  0.20489209 -0.00092683 -0.0499745 ] 1 1.0\n",
      "[ 0.60634805  0.00978344 -0.00192632  0.24241586] 0 1.0\n",
      "[ 0.60654372  0.20493286  0.002922   -0.05087405] 1 1.0\n",
      "[0.61064238 0.00976913 0.00190452 0.24272935] 0 1.0\n",
      "[ 0.61083776  0.20486383  0.00675911 -0.04935223] 1 1.0\n",
      "[ 0.61493504  0.39988821  0.00577206 -0.33989496] 1 1.0\n",
      "[ 0.6229328   0.20468461 -0.00102584 -0.04539745] 0 1.0\n",
      "[ 0.62702649  0.00957738 -0.00193379  0.24696163] 0 1.0\n",
      "[ 0.62721804  0.2047269   0.00300545 -0.04633062] 1 1.0\n",
      "[ 0.63131258  0.39980562  0.00207883 -0.33806379] 1 1.0\n",
      "[ 0.63930869  0.20465415 -0.00468244 -0.04472604] 0 1.0\n",
      "[ 0.64340178  0.00959966 -0.00557696  0.24647586] 0 1.0\n",
      "[ 0.64359377  0.20480081 -0.00064744 -0.04796094] 1 1.0\n",
      "[ 0.64768978  0.00968815 -0.00160666  0.24451764] 0 1.0\n",
      "[ 0.64788355  0.20483301  0.00328369 -0.04867163] 1 1.0\n",
      "[ 0.65198021  0.39990773  0.00231026 -0.34031672] 1 1.0\n",
      "[ 0.65997836  0.20475298 -0.00449608 -0.04690617] 0 1.0\n",
      "[ 0.66407342  0.00969579 -0.0054342   0.24435482] 0 1.0\n",
      "[ 6.64267338e-01  2.04894932e-01 -5.47104751e-04 -5.00372195e-02] 1 1.0\n",
      "[ 0.66836524  0.00978083 -0.00154785  0.24247304] 0 1.0\n",
      "[ 0.66856085  0.20492486  0.00330161 -0.05069772] 1 1.0\n",
      "[ 0.67265935  0.39999931  0.00228766 -0.34233713] 1 1.0\n",
      "[ 0.68065934  0.20484489 -0.00455909 -0.04893369] 0 1.0\n",
      "[ 0.68475623  0.00978861 -0.00553776  0.24230733] 0 1.0\n",
      "[ 0.68495201  0.20498922 -0.00069161 -0.0521172 ] 1 1.0\n",
      "[ 0.68905179  0.00987719 -0.00173396  0.24034744] 0 1.0\n",
      "[ 0.68924933  0.20502387  0.00307299 -0.05288192] 1 1.0\n",
      "[ 0.69334981  0.40010162  0.00201535 -0.34459371] 1 1.0\n",
      "[ 0.70135184  0.20495106 -0.00487652 -0.05127595] 0 1.0\n",
      "[ 0.70545087  0.00989937 -0.00590204  0.23986441] 0 1.0\n",
      "[ 0.70564885  0.20510514 -0.00110475 -0.05467432] 1 1.0\n",
      "[ 0.70975096  0.00999904 -0.00219824  0.23765984] 0 1.0\n",
      "[ 0.70995094  0.20515233  0.00255496 -0.05571566] 1 1.0\n",
      "[0.71405398 0.00999384 0.00144065 0.23777228] 0 1.0\n",
      "[ 0.71425386  0.20509518  0.00619609 -0.05445588] 1 1.0\n",
      "[ 0.71835576  0.40012774  0.00510697 -0.34517747] 1 1.0\n",
      "[ 0.72635832  0.20493352 -0.00179658 -0.0508885 ] 0 1.0\n",
      "[ 0.73045699  0.00983737 -0.00281435  0.24122705] 0 1.0\n",
      "[ 0.73065374  0.20499941  0.0020102  -0.05234227] 1 1.0\n",
      "[0.73475372 0.00984869 0.00096335 0.24097421] 0 1.0\n",
      "[ 0.7349507   0.20495687  0.00578283 -0.05140469] 1 1.0\n",
      "[ 0.73904984  0.39999543  0.00475474 -0.34225749] 1 1.0\n",
      "[ 0.74704974  0.20480615 -0.00209041 -0.048079  ] 0 1.0\n",
      "[ 0.75114587  0.00971424 -0.00305199  0.24394365] 0 1.0\n",
      "[ 0.75134015  0.20487965  0.00182688 -0.04970039] 1 1.0\n",
      "[ 0.75543774  0.39997536  0.00083288 -0.34180636] 1 1.0\n",
      "[ 0.76343725  0.20484157 -0.00600325 -0.04886091] 0 1.0\n",
      "[ 0.76753408  0.00980621 -0.00698047  0.24192191] 0 1.0\n",
      "[ 0.76773021  0.20502717 -0.00214203 -0.05295464] 1 1.0\n",
      "[ 0.77183075  0.009936   -0.00320112  0.23905169] 0 1.0\n",
      "[ 0.77202947  0.20510354  0.00157991 -0.05463924] 1 1.0\n",
      "[7.76131542e-01 9.95896692e-03 4.87124987e-04 2.38541741e-01] 0 1.0\n",
      "[ 0.77633072  0.20507396  0.00525796 -0.05398749] 1 1.0\n",
      "[ 0.7804322   0.40012012  0.00417821 -0.34500686] 1 1.0\n",
      "[ 0.7884346   0.20493898 -0.00272193 -0.05100932] 0 1.0\n",
      "[ 0.79253338  0.00985617 -0.00374211  0.24081357] 0 1.0\n",
      "[ 0.79273051  0.20503137  0.00107416 -0.05304737] 1 1.0\n",
      "[7.96831133e-01 9.89403772e-03 1.32102318e-05 2.39974271e-01] 0 1.0\n",
      "[ 0.79702901  0.2050158   0.0048127  -0.05270449] 1 1.0\n",
      "[ 0.80112933  0.40006841  0.00375861 -0.34386509] 1 1.0\n",
      "[ 0.8091307   0.20489319 -0.0031187  -0.04999931] 0 1.0\n",
      "[ 0.81322856  0.0098161  -0.00411868  0.24169802] 0 1.0\n",
      "[ 8.13424884e-01  2.04996642e-01  7.15278187e-04 -5.22812017e-02] 1 1.0\n",
      "[ 8.17524817e-01  9.86444232e-03 -3.30345847e-04  2.40627315e-01] 0 1.0\n",
      "[ 0.81772211  0.20499111  0.0044822  -0.05215979] 1 1.0\n",
      "[ 0.82182193  0.40004851  0.003439   -0.34342519] 1 1.0\n",
      "[ 0.8298229   0.2048778  -0.0034295  -0.04965979] 0 1.0\n",
      "[ 0.83392045  0.00980519 -0.00442269  0.24193913] 0 1.0\n",
      "[ 8.34116558e-01  2.04990039e-01  4.16087631e-04 -5.21355454e-02] 1 1.0\n",
      "[ 8.38216359e-01  9.86212381e-03 -6.26623277e-04  2.40678631e-01] 0 1.0\n",
      "[ 0.8384136   0.20499302  0.00418695 -0.05220188] 1 1.0\n",
      "[ 0.84251346  0.40005469  0.00314291 -0.34356086] 1 1.0\n",
      "[ 0.85051456  0.20488816 -0.00372831 -0.04988851] 0 1.0\n",
      "[ 0.85461232  0.00981987 -0.00472608  0.24161578] 0 1.0\n",
      "[ 8.54808716e-01  2.05009013e-01  1.06239972e-04 -5.25541228e-02] 1 1.0\n",
      "[ 0.8589089   0.00988554 -0.00094484  0.24016232] 0 1.0\n",
      "[ 0.85910661  0.20502097  0.0038584  -0.05281848] 1 1.0\n",
      "[ 0.86320703  0.40008739  0.00280203 -0.34428156] 1 1.0\n",
      "[ 0.87120877  0.20492569 -0.0040836  -0.05071636] 0 1.0\n",
      "[ 0.87530729  0.00986253 -0.00509792  0.24067536] 0 1.0\n",
      "[ 8.75504539e-01  2.05056931e-01 -2.84416975e-04 -5.36112198e-02] 1 1.0\n",
      "[ 0.87960568  0.00993906 -0.00135664  0.23898196] 0 1.0\n",
      "[ 0.87980446  0.20508037  0.003423   -0.05412858] 1 1.0\n",
      "[0.88390607 0.0099095  0.00234043 0.23963236] 0 1.0\n",
      "[ 0.88410426  0.20499794  0.00713307 -0.05231142] 1 1.0\n",
      "[ 0.88820421  0.40001689  0.00608684 -0.34273529] 1 1.0\n",
      "[ 8.96204553e-01  2.04808872e-01 -7.67860872e-04 -4.81391691e-02] 0 1.0\n",
      "[ 0.90030073  0.00969794 -0.00173064  0.24430139] 0 1.0\n",
      "[ 0.90049469  0.20484457  0.00315538 -0.04892692] 1 1.0\n",
      "[0.90459158 0.00967751 0.00217685 0.24474988] 0 1.0\n",
      "[ 0.90478513  0.2047683   0.00707184 -0.04724562] 1 1.0\n",
      "[ 0.9088805   0.39978814  0.00612693 -0.33768895] 1 1.0\n",
      "[ 9.16876259e-01  2.04579540e-01 -6.26848496e-04 -4.30802408e-02] 0 1.0\n",
      "[ 0.92096785  0.00946658 -0.00148845  0.24940484] 0 1.0\n",
      "[ 0.92115718  0.20460976  0.00349964 -0.0437472 ] 1 1.0\n",
      "[0.92524938 0.0094378  0.0026247  0.25003784] 0 1.0\n",
      "[ 0.92543813  0.20452217  0.00762546 -0.04181605] 1 1.0\n",
      "[ 0.92952858  0.39953395  0.00678914 -0.33208335] 1 1.0\n",
      "[ 9.37519255e-01  2.04316024e-01  1.47468293e-04 -3.72672203e-02] 0 1.0\n",
      "[ 9.41605576e-01  9.19195847e-03 -5.97876113e-04  2.55462231e-01] 0 1.0\n",
      "[ 0.94178942  0.20432244  0.00451137 -0.03740922] 1 1.0\n",
      "[0.94587586 0.00913609 0.00376318 0.25669367] 0 1.0\n",
      "[ 0.94605859  0.20420411  0.00889706 -0.03479992] 1 1.0\n",
      "[ 0.95014267  0.39919735  0.00820106 -0.3246625 ] 1 1.0\n",
      "[ 0.95812661  0.2039596   0.00170781 -0.02940463] 0 1.0\n",
      "[0.96220581 0.00881319 0.00111972 0.26381664] 0 1.0\n",
      "[ 0.96238207  0.20391915  0.00639605 -0.02851291] 1 1.0\n",
      "[0.96646045 0.00870606 0.00582579 0.26618116] 0 1.0\n",
      "[ 0.96663457  0.20374438  0.01114941 -0.02465858] 1 1.0\n",
      "[ 0.97070946  0.39870468  0.01065624 -0.313803  ] 1 1.0\n",
      "[ 0.97868356  0.20343256  0.00438018 -0.01777857] 0 1.0\n",
      "[0.98275221 0.00824806 0.00402461 0.27628313] 0 1.0\n",
      "[ 0.98291717  0.20331237  0.00955027 -0.01512772] 1 1.0\n",
      "[ 0.98698342  0.39829606  0.00924772 -0.30478219] 1 1.0\n",
      "[ 0.99494934  0.20304355  0.00315208 -0.00919716] 0 1.0\n",
      "[0.99901021 0.00787654 0.00296813 0.28447862] 0 1.0\n",
      "[ 0.99916774  0.20295603  0.00865771 -0.0072667 ] 1 1.0\n",
      "[ 1.00322686  0.39795275  0.00851237 -0.29720549] 1 1.0\n",
      "[ 1.01118591  0.2027105   0.00256826 -0.00185011] 0 1.0\n",
      "[1.01524012 0.00755181 0.00253126 0.29164203] 0 1.0\n",
      "[ 1.01539116e+00  2.02637577e-01  8.36409983e-03 -2.41497607e-04] 1 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.01944391  0.39763858  0.00835927 -0.29027376] 1 1.0\n",
      "[1.02739668 0.20239844 0.00255379 0.00503382] 0 1.0\n",
      "[1.03144465 0.00723995 0.00265447 0.29852141] 0 1.0\n",
      "[1.03158945 0.20232397 0.0086249  0.00667683] 1 1.0\n",
      "[ 1.03563593  0.39732117  0.00875844 -0.2832724 ] 1 1.0\n",
      "[1.04358235 0.2020754  0.00309299 0.01215997] 0 1.0\n",
      "[ 1.04762386  0.39715286  0.00333619 -0.27954548] 1 1.0\n",
      "[ 1.05556692  0.20198347 -0.00225472  0.0141878 ] 0 1.0\n",
      "[ 1.05960659  0.00689393 -0.00197097  0.30615849] 0 1.0\n",
      "[1.05974447 0.20204391 0.0041522  0.01285462] 1 1.0\n",
      "[1.06378535 0.00686266 0.0044093  0.30684472] 0 1.0\n",
      "[1.0639226  0.2019215  0.01054619 0.01555563] 1 1.0\n",
      "[ 1.06796103  0.39689063  0.0108573  -0.27378128] 1 1.0\n",
      "[1.07589884 0.20161546 0.00538168 0.02230619] 0 1.0\n",
      "[ 1.07993115  0.39665982  0.0058278  -0.26867391] 1 1.0\n",
      "[1.08786435e+00 2.01455190e-01 4.54323057e-04 2.58414341e-02] 0 1.0\n",
      "[1.09189345e+00 6.32672650e-03 9.71151739e-04 3.18667670e-01] 0 1.0\n",
      "[1.09201999 0.20143483 0.00734451 0.02629117] 1 1.0\n",
      "[ 1.09604868  0.39645069  0.00787033 -0.26406547] 1 1.0\n",
      "[1.1039777  0.20121729 0.00258902 0.03108941] 0 1.0\n",
      "[1.10800204 0.00605831 0.00321081 0.32458808] 0 1.0\n",
      "[1.10812321 0.2011344  0.00970257 0.03291943] 1 1.0\n",
      "[ 1.1121459   0.39611588  0.01036096 -0.25668651] 1 1.0\n",
      "[1.12006821 0.20084754 0.00522723 0.03924634] 0 1.0\n",
      "[ 1.12408516  0.39589415  0.00601215 -0.25178278] 1 1.0\n",
      "[1.13200305e+00 2.00686864e-01 9.76498684e-04 4.27904212e-02] 0 1.0\n",
      "[1.13601678 0.00555092 0.00183231 0.33578128] 0 1.0\n",
      "[1.1361278  0.20064675 0.00854793 0.04367673] 1 1.0\n",
      "[ 1.14014074  0.39564509  0.00942147 -0.24629703] 1 1.0\n",
      "[1.14805364 0.20038986 0.00449553 0.04934269] 0 1.0\n",
      "[ 1.15206144  0.39544706  0.00548238 -0.24191847] 1 1.0\n",
      "[1.15997038e+00 2.00247225e-01 6.44011124e-04 5.24886871e-02] 0 1.0\n",
      "[1.16397532 0.00511605 0.00169378 0.34537474] 0 1.0\n",
      "[1.16407764 0.20021386 0.00860128 0.0532264 ] 1 1.0\n",
      "[ 1.16808192  0.39521143  0.00966581 -0.23673039] 1 1.0\n",
      "[1.17598615 0.19995273 0.0049312  0.05898569] 0 1.0\n",
      "[ 1.1799852   0.39500363  0.00611091 -0.23213734] 1 1.0\n",
      "[1.18788528 0.1997949  0.00146817 0.06246689] 0 1.0\n",
      "[1.19188117 0.00465193 0.0027175  0.35561267] 0 1.0\n",
      "[1.19197421 0.19973514 0.00982976 0.06378788] 1 1.0\n",
      "[ 1.19596892  0.39471478  0.01110552 -0.22577756] 1 1.0\n",
      "[1.20386321 0.19943589 0.00658996 0.07038767] 0 1.0\n",
      "[ 1.20785193  0.39446275  0.00799772 -0.22020882] 1 1.0\n",
      "[1.21574118 0.19922739 0.00359354 0.07498614] 0 1.0\n",
      "[ 1.21972573  0.39429764  0.00509326 -0.21656084] 1 1.0\n",
      "[1.22761169e+00 1.99103253e-01 7.62047439e-04 7.77243599e-02] 0 1.0\n",
      "[ 1.23159375  0.39421427  0.00231653 -0.21471804] 1 1.0\n",
      "[ 1.23947804  0.19905928 -0.00197783  0.07869472] 0 1.0\n",
      "[ 1.24345922e+00  3.94209527e-01 -4.03931720e-04 -2.14611557e-01] 1 1.0\n",
      "[ 1.25134341  0.19909335 -0.00469616  0.07794392] 0 1.0\n",
      "[ 1.25532528  0.00403904 -0.00313728  0.3691415 ] 0 1.0\n",
      "[1.25540606 0.19920542 0.00424555 0.07547101] 1 1.0\n",
      "[ 1.25939017  0.39426626  0.00575497 -0.21586942] 1 1.0\n",
      "[1.26727549 0.19906251 0.00143758 0.07862331] 0 1.0\n",
      "[ 1.27125674  0.39416382  0.00301004 -0.21360571] 1 1.0\n",
      "[ 1.27914002e+00  1.98998963e-01 -1.26207063e-03  8.00251972e-02] 0 1.0\n",
      "[ 1.28312000e+00  3.94138984e-01  3.38433315e-04 -2.13055649e-01] 1 1.0\n",
      "[ 1.29100278  0.1990122  -0.00392268  0.07973402] 0 1.0\n",
      "[ 1.29498302  0.0039467  -0.002328    0.37117675] 0 1.0\n",
      "[1.29506196 0.19910164 0.00509554 0.07776069] 1 1.0\n",
      "[ 1.29904399  0.39415018  0.00665075 -0.21331023] 1 1.0\n",
      "[1.30692699 0.19893378 0.00238454 0.0814632 ] 0 1.0\n",
      "[ 1.31090567  0.39402146  0.00401381 -0.21046644] 1 1.0\n",
      "[ 1.31878610e+00  1.98842352e-01 -1.95520074e-04  8.34799216e-02] 0 1.0\n",
      "[ 1.32276294  0.39396711  0.00147408 -0.20926469] 1 1.0\n",
      "[ 1.33064229  0.19882411 -0.00271122  0.08388287] 0 1.0\n",
      "[ 1.33461877e+00  3.74112583e-03 -1.03355793e-03  3.75709173e-01] 0 1.0\n",
      "[1.33469359 0.19887774 0.00648063 0.08270054] 1 1.0\n",
      "[ 1.33867115  0.3939062   0.00813464 -0.20793071] 1 1.0\n",
      "[1.34654927 0.19866888 0.00397602 0.08730714] 0 1.0\n",
      "[ 1.35052265  0.39373361  0.00572216 -0.2041187 ] 1 1.0\n",
      "[1.35839732 0.1985303  0.00163979 0.09036378] 0 1.0\n",
      "[ 1.36236793  0.39362871  0.00344707 -0.20180134] 1 1.0\n",
      "[ 1.37024050e+00  1.98457627e-01 -5.88960538e-04  9.19669741e-02] 0 1.0\n",
      "[ 1.37420965e+00  3.93588015e-01  1.25037894e-03 -2.00901711e-01] 1 1.0\n",
      "[ 1.38208141  0.1984482  -0.00276766  0.09217539] 0 1.0\n",
      "[ 1.38605038e+00  3.93609714e-01 -9.24147507e-04 -2.01379446e-01] 1 1.0\n",
      "[ 1.39392257  0.19850099 -0.00495174  0.09101181] 0 1.0\n",
      "[ 1.39789259  0.39369357 -0.0031315  -0.20322926] 1 1.0\n",
      "[ 1.40576646  0.19861654 -0.00719609  0.08846418] 0 1.0\n",
      "[ 1.40973879  0.00359847 -0.0054268   0.37886808] 0 1.0\n",
      "[1.40981076 0.19879707 0.00215056 0.08447902] 1 1.0\n",
      "[ 1.4137867   0.39388813  0.00384014 -0.20752462] 1 1.0\n",
      "[ 1.42166447e+00  1.98711475e-01 -3.10352220e-04  8.63671947e-02] 0 1.0\n",
      "[ 1.42563870e+00  3.93837873e-01  1.41699167e-03 -2.06413632e-01] 1 1.0\n",
      "[ 1.43351545  0.19869569 -0.00271128  0.08671595] 0 1.0\n",
      "[ 1.43748937e+00  3.93856398e-01 -9.76962033e-04 -2.06821157e-01] 1 1.0\n",
      "[ 1.4453665   0.19874843 -0.00511339  0.08555343] 0 1.0\n",
      "[ 1.44934146  0.3939433  -0.00340232 -0.20873838] 1 1.0\n",
      "[ 1.45722033  0.19887017 -0.00757708  0.08286935] 0 1.0\n",
      "[ 1.46119773  0.39409991 -0.0059197  -0.2121945 ] 1 1.0\n",
      "[ 1.46907973  0.19906309 -0.01016359  0.07861522] 0 1.0\n",
      "[ 1.47306099  0.39432926 -0.00859128 -0.21725695] 1 1.0\n",
      "[ 1.48094758  0.19933117 -0.01293642  0.07270359] 0 1.0\n",
      "[ 1.4849342   0.00439705 -0.01148235  0.3612771 ] 0 1.0\n",
      "[ 1.48502214  0.19968031 -0.00425681  0.06499578] 1 1.0\n",
      "[ 1.48901575  0.39486303 -0.00295689 -0.22902715] 1 1.0\n",
      "[ 1.49691301  0.19978346 -0.00753744  0.0627216 ] 0 1.0\n",
      "[ 1.50090868  0.39501267 -0.006283   -0.23232987] 1 1.0\n",
      "[ 1.50880893  0.19998105 -0.0109296   0.05836459] 0 1.0\n",
      "[ 1.51280855  0.39525799 -0.00976231 -0.23774657] 1 1.0\n",
      "[ 1.52071371  0.20027686 -0.01451724  0.05184112] 0 1.0\n",
      "[ 1.52471925  0.00536605 -0.01348042  0.33990861] 0 1.0\n",
      "[ 1.52482657  0.20067719 -0.00668225  0.0430054 ] 1 1.0\n",
      "[ 1.52884012  0.39589432 -0.00582214 -0.25177833] 1 1.0\n",
      "[ 1.536758    0.20085599 -0.0108577   0.03906251] 0 1.0\n",
      "[ 1.54077512  0.39613194 -0.01007645 -0.25702625] 1 1.0\n",
      "[ 1.54869776  0.20115529 -0.01521698  0.03246145] 0 1.0\n",
      "[ 1.55272087  0.00625483 -0.01456775  0.32030468] 0 1.0\n",
      "[ 1.55284596  0.20158118 -0.00816166  0.02306347] 1 1.0\n",
      "[ 1.55687759  0.39681922 -0.00770039 -0.27218334] 1 1.0\n",
      "[ 1.56481397  0.20180799 -0.01314405  0.01806095] 0 1.0\n",
      "[ 1.56885013  0.00687698 -0.01278283  0.30656796] 0 1.0\n",
      "[ 1.56898767  0.20217873 -0.00665148  0.00988122] 1 1.0\n",
      "[ 1.57303124  0.39739544 -0.00645385 -0.28489288] 1 1.0\n",
      "[ 1.58097915  0.20236612 -0.01215171  0.00574757] 0 1.0\n",
      "[ 1.58502648  0.00742053 -0.01203676  0.29457185] 0 1.0\n",
      "[ 1.58517489  0.202712   -0.00614532 -0.00188285] 1 1.0\n",
      "[ 1.58922913  0.39792155 -0.00618298 -0.29649835] 1 1.0\n",
      "[ 1.59718756  0.20288828 -0.01211294 -0.00577183] 0 1.0\n",
      "[ 1.60124532  0.00794212 -0.01222838  0.28306484] 0 1.0\n",
      "[ 1.60140417  0.20323634 -0.00656708 -0.01344963] 1 1.0\n",
      "[ 1.60546889  0.39845185 -0.00683608 -0.3081973 ] 1 1.0\n",
      "[ 1.61343793  0.20342797 -0.01300002 -0.0176781 ] 0 1.0\n",
      "[ 1.61750649  0.00849484 -0.01335358  0.27087498] 0 1.0\n",
      "[ 1.61767639  0.20380478 -0.00793609 -0.02598964] 1 1.0\n",
      "[ 1.62175248  0.39903963 -0.00845588 -0.32116588] 1 1.0\n",
      "[ 1.62973327  0.20403912 -0.0148792  -0.03116156] 0 1.0\n",
      "[ 1.63381406  0.00913367 -0.01550243  0.25678993] 0 1.0\n",
      "[ 1.63399673  0.20447348 -0.01036663 -0.04074211] 1 1.0\n",
      "[ 1.6380862   0.0095017  -0.01118147  0.2486521 ] 0 1.0\n",
      "[ 1.63827623  0.20478154 -0.00620843 -0.04753663] 1 1.0\n",
      "[ 1.64237186  0.39999196 -0.00715916 -0.34217188] 1 1.0\n",
      "[ 1.6503717   0.20497259 -0.0140026  -0.0517551 ] 0 1.0\n",
      "[ 1.65447115  0.01005419 -0.0150377   0.2364772 ] 0 1.0\n",
      "[ 1.65467224  0.20538772 -0.01030816 -0.06091088] 1 1.0\n",
      "[ 1.65877999  0.01041507 -0.01152637  0.22850201] 0 1.0\n",
      "[ 1.65898829  0.20569983 -0.00695633 -0.06779434] 1 1.0\n",
      "[ 1.66310229  0.0106783  -0.00831222  0.22268573] 0 1.0\n",
      "[ 1.66331586  0.20591806 -0.00385851 -0.07260757] 1 1.0\n",
      "[ 1.66743422  0.40109512 -0.00531066 -0.36650537] 1 1.0\n",
      "[ 1.67545612  0.20604904 -0.01264077 -0.07550169] 0 1.0\n",
      "[ 1.6795771   0.01111056 -0.0141508   0.21316637] 0 1.0\n",
      "[ 1.67979931  0.20643194 -0.00988747 -0.08394656] 1 1.0\n",
      "[ 1.68392795  0.01145311 -0.0115664   0.20560053] 0 1.0\n",
      "[ 1.68415701  0.20673853 -0.00745439 -0.09070847] 1 1.0\n",
      "[ 1.68829178  0.01172422 -0.00926856  0.19961331] 0 1.0\n",
      "[ 1.68852627  0.2069775  -0.0052763  -0.09597895] 1 1.0\n",
      "[ 1.69266582  0.01193157 -0.00719587  0.19503465] 0 1.0\n",
      "[ 1.69290445  0.20715571 -0.00329518 -0.09990955] 1 1.0\n",
      "[ 1.69704756  0.01208114 -0.00529337  0.19173194] 0 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.69728919e+00  2.07278410e-01 -1.45873359e-03 -1.02616115e-01] 1 1.0\n",
      "[ 1.70143475  0.40242124 -0.00351106 -0.39575891] 1 1.0\n",
      "[ 1.70948318  0.20734928 -0.01142623 -0.10418502] 0 1.0\n",
      "[ 1.71363017  0.01239292 -0.01350993  0.18487118] 0 1.0\n",
      "[ 1.71387802  0.20770554 -0.00981251 -0.11204282] 1 1.0\n",
      "[ 1.71803213  0.01272556 -0.01205337  0.17752824] 0 1.0\n",
      "[ 1.71828665  0.20801791 -0.0085028  -0.11893261] 1 1.0\n",
      "[ 1.722447    0.01301881 -0.01088145  0.17105567] 0 1.0\n",
      "[ 1.72270738  0.20829481 -0.00746034 -0.12504006] 1 1.0\n",
      "[ 1.72687328  0.01328052 -0.00996114  0.16527991] 0 1.0\n",
      "[ 1.72713889  0.20854364 -0.00665554 -0.13052876] 1 1.0\n",
      "[ 1.73130976  0.01351766 -0.00926612  0.16004701] 0 1.0\n",
      "[ 1.73158011  0.20877103 -0.00606518 -0.13554468] 1 1.0\n",
      "[ 1.73575553  0.01373648 -0.00877607  0.15521862] 0 1.0\n",
      "[ 1.73603026  0.20898298 -0.0056717  -0.14021998] 1 1.0\n",
      "[ 1.74020992  0.01394272 -0.0084761   0.15066824] 0 1.0\n",
      "[ 1.74048878  0.20918501 -0.00546274 -0.14467662] 1 1.0\n",
      "[ 1.74467248  0.01414171 -0.00835627  0.14627792] 0 1.0\n",
      "[ 1.74495531  0.20938233 -0.00543071 -0.14902949] 1 1.0\n",
      "[ 1.74914296  0.01433856 -0.0084113   0.14193522] 0 1.0\n",
      "[ 1.74942973  0.20957996 -0.00557259 -0.15338941] 1 1.0\n",
      "[ 1.75362133  0.01453824 -0.00864038  0.13753029] 0 1.0\n",
      "[ 1.75391209  0.20978288 -0.00588978 -0.15786598] 1 1.0\n",
      "[ 1.75810775  0.01474574 -0.0090471   0.13295307] 0 1.0\n",
      "[ 1.75840267  0.20999611 -0.00638804 -0.16257031] 1 1.0\n",
      "[ 1.76260259  0.01496619 -0.00963944  0.12809054] 0 1.0\n",
      "[ 1.76290191  0.21022489 -0.00707763 -0.16761787] 1 1.0\n",
      "[ 1.76710641  0.01520496 -0.01042999  0.1228239 ] 0 1.0\n",
      "[ 1.76741051  0.21047478 -0.00797351 -0.17313125] 1 1.0\n",
      "[ 1.77162     0.01546785 -0.01143614  0.11702566] 0 1.0\n",
      "[ 1.77192936  0.21075177 -0.00909562 -0.17924323] 1 1.0\n",
      "[ 1.7761444   0.01576116 -0.01268049  0.11055652] 0 1.0\n",
      "[ 1.77645962  0.21106249 -0.01046936 -0.1860999 ] 1 1.0\n",
      "[ 1.78068087  0.01609189 -0.01419135  0.10326205] 0 1.0\n",
      "[ 1.78100271 -0.17882384 -0.01212611  0.39143409] 0 1.0\n",
      "[ 1.77742623  0.01646809 -0.00429743  0.09495274] 1 1.0\n",
      "[ 1.77775559  0.21165137 -0.00239838 -0.19908292] 1 1.0\n",
      "[ 1.78198862  0.0165638  -0.00638004  0.09284247] 0 1.0\n",
      "[ 1.7823199   0.21177661 -0.00452319 -0.20184651] 1 1.0\n",
      "[ 1.78655543  0.01671964 -0.00856012  0.08940614] 0 1.0\n",
      "[ 1.78688982  0.21196324 -0.00677199 -0.20596516] 1 1.0\n",
      "[ 1.79112909  0.01693878 -0.0108913   0.08457387] 0 1.0\n",
      "[ 1.79146786 -0.17802537 -0.00919982  0.37380077] 0 1.0\n",
      "[ 1.78790735e+00  1.72260481e-02 -1.72380375e-03  7.82313253e-02] 1 1.0\n",
      "[ 1.78825187e+00  2.12372668e-01 -1.59177246e-04 -2.14994968e-01] 1 1.0\n",
      "[ 1.79249933  0.01725299 -0.00445908  0.07763774] 0 1.0\n",
      "[ 1.79284439  0.21243858 -0.00290632 -0.2164487 ] 1 1.0\n",
      "[ 1.79709316  0.0173583  -0.0072353   0.07531604] 0 1.0\n",
      "[ 1.79744033  0.21258322 -0.00572897 -0.21964084] 1 1.0\n",
      "[ 1.80169199  0.01754363 -0.01012179  0.07122943] 0 1.0\n",
      "[ 1.80204286 -0.17743176 -0.0086972   0.36070178] 0 1.0\n",
      "[ 1.79849423e+00  1.78127350e-02 -1.48316763e-03  6.52891727e-02] 1 1.0\n",
      "500.0\n"
     ]
    }
   ],
   "source": [
    "play(\"CartPole-v1\", agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
