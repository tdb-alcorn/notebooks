{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = [\n",
    "    \"add 1 to 2\",\n",
    "    \"let x be 2\\nlet y be 5\\nadd x to y\",\n",
    "    \"let x be 3\",\n",
    "    \"does x = y ?\",\n",
    "    \"let x be 'foo'\\nlet y be 'foo'\\ndoes x = y ?\",\n",
    "    \"send 'hello world' to out\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, namedtuple\n",
    "from enum import Enum\n",
    "from sys import stdout\n",
    "\n",
    "class TokenType(Enum):\n",
    "    IDENTIFIER = 1\n",
    "    NUMERAL = 2\n",
    "    STRING = 3\n",
    "    KEYWORD = 4\n",
    "    OPERATOR = 5\n",
    "    SEPARATOR = 6\n",
    "    COMMENT = 7\n",
    "\n",
    "Token = namedtuple('Token', ['value', 'type'])\n",
    "    \n",
    "keywords = set([\n",
    "    'let',\n",
    "    'does',\n",
    "    'send',\n",
    "    'to',\n",
    "    'be',\n",
    "    'add',\n",
    "])\n",
    "operators = set([\n",
    "    '=',\n",
    "    '?',\n",
    "])\n",
    "\n",
    "memory = defaultdict(lambda:0)\n",
    "memory['out'] = stdout\n",
    "    \n",
    "def token_type(t):\n",
    "    if t[0].isdigit():\n",
    "        return TokenType.NUMERAL\n",
    "    elif t[0] == ',':\n",
    "        return TokenType.SEPARATOR\n",
    "    elif t in keywords:\n",
    "        return TokenType.KEYWORD\n",
    "    elif t in operators:\n",
    "        return TokenType.OPERATOR\n",
    "    return TokenType.IDENTIFIER\n",
    "\n",
    "def tokenize(s):\n",
    "    current_token = ''\n",
    "    reading_string = False\n",
    "    reading_comment = False\n",
    "    out = []\n",
    "    for char in s:\n",
    "        if char == ' ' and not reading_string and not reading_comment:\n",
    "            if len(current_token) > 0:\n",
    "                out.append(Token(current_token, token_type(current_token)))\n",
    "                current_token = ''\n",
    "        elif char == '\\'' and not reading_comment:\n",
    "            if reading_string:\n",
    "                out.append(Token(current_token, TokenType.STRING))\n",
    "                current_token = ''\n",
    "            reading_string = not reading_string\n",
    "        elif char == '#':\n",
    "            out.append(Token(current_token, token_type(current_token)))\n",
    "            current_token = ''\n",
    "            reading_comment = not reading_comment\n",
    "        else:\n",
    "            current_token += char\n",
    "    if len(current_token) > 0:\n",
    "        if reading_comment:\n",
    "            out.append(Token(current_token, TokenType.COMMENT))\n",
    "        else:\n",
    "            out.append(Token(current_token, token_type(current_token)))\n",
    "    return out\n",
    "\n",
    "def get_value(t):\n",
    "    if t.type == TokenType.NUMERAL:\n",
    "        if '.' in t.value:\n",
    "            return float(t.value)\n",
    "        else:\n",
    "            return int(t.value)\n",
    "    elif t.type == TokenType.STRING:\n",
    "        return t.value\n",
    "    elif t.type == TokenType.IDENTIFIER:\n",
    "        return memory[t.value]\n",
    "    return t.value\n",
    "\n",
    "def get_operation(t):\n",
    "    if t.type != TokenType.OPERATOR:\n",
    "        raise Exception('Not a valid operator')\n",
    "    if t.value == '=':\n",
    "        return lambda a, b: a == b\n",
    "    raise NotImplementedError\n",
    "    \n",
    "def send(address, msg):\n",
    "    address.write(msg)\n",
    "    \n",
    "def cmpl(program):\n",
    "    lines = program.split('\\n')\n",
    "    results = []\n",
    "    for line in lines:\n",
    "        tokens = tokenize(line)\n",
    "        if tokens[0].type != TokenType.KEYWORD:\n",
    "            raise Exception('Not a valid expression (for now)')\n",
    "        if tokens[0].value == 'add':\n",
    "            a = get_value(tokens[1])\n",
    "            b = None\n",
    "            if tokens[2].type != TokenType.KEYWORD:\n",
    "                b = get_value(tokens[2]) \n",
    "            else:\n",
    "                b = get_value(tokens[3])\n",
    "            results.append(a + b)\n",
    "        elif tokens[0].value == 'let':\n",
    "            identifier = tokens[1].value\n",
    "            value = get_value(tokens[3])\n",
    "            memory[identifier] = value\n",
    "            results.append('Value %s stored in variable %s' % (str(value), identifier))\n",
    "        elif tokens[0].value == 'does':\n",
    "            a = get_value(tokens[1])\n",
    "            op = get_operation(tokens[2])\n",
    "            b = get_value(tokens[1])\n",
    "            results.append(op(a, b))\n",
    "        elif tokens[0].value == 'send':\n",
    "            msg = get_value(tokens[1])\n",
    "            address_idx = [i+1 for i in range(len(tokens)) if tokens[i].value == 'to'][0]\n",
    "            address = get_value(tokens[address_idx])\n",
    "            send(address, msg)\n",
    "#         results.append(tokens)\n",
    "    return results\n",
    "\n",
    "\n",
    "# temporary rule: everything is an expression.\n",
    "# the first token in every expression is going to be a keyword that determines what \n",
    "# the expression is supposed to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[3],\n",
       " ['Value 2 stored in variable x', 'Value 5 stored in variable y', 7],\n",
       " ['Value 3 stored in variable x'],\n",
       " [True],\n",
       " ['Value foo stored in variable x', 'Value foo stored in variable y', True],\n",
       " []]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[cmpl(t) for t in tests]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add 1 to 2\n",
      "add\n",
      "1\n",
      "to\n",
      "2\n",
      "[Token(value='add', type=<TokenType.KEYWORD: 4>), Token(value='1', type=<TokenType.NUMERAL: 2>), Token(value='to', type=<TokenType.KEYWORD: 4>), Token(value='2', type=<TokenType.NUMERAL: 2>)]\n",
      "\n",
      "let x be 2\n",
      "let\n",
      "x\n",
      "be\n",
      "2\n",
      "[Token(value='let', type=<TokenType.KEYWORD: 4>), Token(value='x', type=<TokenType.IDENTIFIER: 1>), Token(value='be', type=<TokenType.KEYWORD: 4>), Token(value='2', type=<TokenType.NUMERAL: 2>)]\n",
      "let y be 5\n",
      "let\n",
      "y\n",
      "be\n",
      "5\n",
      "[Token(value='let', type=<TokenType.KEYWORD: 4>), Token(value='y', type=<TokenType.IDENTIFIER: 1>), Token(value='be', type=<TokenType.KEYWORD: 4>), Token(value='5', type=<TokenType.NUMERAL: 2>)]\n",
      "add x to y\n",
      "add\n",
      "x\n",
      "to\n",
      "y\n",
      "[Token(value='add', type=<TokenType.KEYWORD: 4>), Token(value='x', type=<TokenType.IDENTIFIER: 1>), Token(value='to', type=<TokenType.KEYWORD: 4>), Token(value='y', type=<TokenType.IDENTIFIER: 1>)]\n",
      "\n",
      "let x be 3\n",
      "let\n",
      "x\n",
      "be\n",
      "3\n",
      "[Token(value='let', type=<TokenType.KEYWORD: 4>), Token(value='x', type=<TokenType.IDENTIFIER: 1>), Token(value='be', type=<TokenType.KEYWORD: 4>), Token(value='3', type=<TokenType.NUMERAL: 2>)]\n",
      "\n",
      "does x = y ?\n",
      "does\n",
      "x\n",
      "=\n",
      "y\n",
      "?\n",
      "[Token(value='does', type=<TokenType.KEYWORD: 4>), Token(value='x', type=<TokenType.IDENTIFIER: 1>), Token(value='=', type=<TokenType.OPERATOR: 5>), Token(value='y', type=<TokenType.IDENTIFIER: 1>), Token(value='?', type=<TokenType.OPERATOR: 5>)]\n",
      "\n",
      "let x be 'foo'\n",
      "let\n",
      "x\n",
      "be\n",
      "f\n",
      "o\n",
      "o\n",
      "'\n",
      "[Token(value='let', type=<TokenType.KEYWORD: 4>), Token(value='x', type=<TokenType.IDENTIFIER: 1>), Token(value='be', type=<TokenType.KEYWORD: 4>), Token(value='foo', type=<TokenType.STRING: 3>)]\n",
      "let y be 'foo'\n",
      "let\n",
      "y\n",
      "be\n",
      "f\n",
      "o\n",
      "o\n",
      "'\n",
      "[Token(value='let', type=<TokenType.KEYWORD: 4>), Token(value='y', type=<TokenType.IDENTIFIER: 1>), Token(value='be', type=<TokenType.KEYWORD: 4>), Token(value='foo', type=<TokenType.STRING: 3>)]\n",
      "does x = y ?send 'hello world' to out\n",
      "does\n",
      "x\n",
      "=\n",
      "y\n",
      "?send\n",
      "h\n",
      "e\n",
      "l\n",
      "l\n",
      "o\n",
      " \n",
      "w\n",
      "o\n",
      "r\n",
      "l\n",
      "d\n",
      "'\n",
      "to\n",
      "out\n",
      "[Token(value='does', type=<TokenType.KEYWORD: 4>), Token(value='x', type=<TokenType.IDENTIFIER: 1>), Token(value='=', type=<TokenType.OPERATOR: 5>), Token(value='y', type=<TokenType.IDENTIFIER: 1>), Token(value='?send', type=<TokenType.IDENTIFIER: 1>), Token(value='hello world', type=<TokenType.STRING: 3>), Token(value='to', type=<TokenType.KEYWORD: 4>), Token(value='out', type=<TokenType.KEYWORD: 4>)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in tests:\n",
    "    for l in t.split('\\n'):\n",
    "        print(l)\n",
    "        print(tokenize(l))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
